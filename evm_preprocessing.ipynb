{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys, math, os, logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "import platform\n",
    "import glob\n",
    "import ctypes\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ideal_bandpassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def shiftdim(x, n):\n",
    "    return x.transpose(np.roll(range(x.ndim), -n))\n",
    "\n",
    "\n",
    "def repmat(a,m):\n",
    "    #First, pad out a so it has same dimensionality as m\n",
    "    for i in range(0,m.ndim-a.ndim):\n",
    "        a = np.expand_dims(a,1)\n",
    "    #Now just use numpy tile and return result\n",
    "    return np.tile(a,m.shape)\n",
    "\n",
    "\n",
    "def ideal_bandpassing(input, dim, wl, wh, samplingRate):\n",
    "    # if dim is greater than the dimensionality (2d, 3d etc) of the input, quit\n",
    "    if (dim > len(input.shape)):\n",
    "        print('Exceed maximum dimension')\n",
    "        return\n",
    "\n",
    "    # This has the effect that input_shifted[0] = input[dim]\n",
    "    input_shifted = shiftdim(input, dim - 1)\n",
    "\n",
    "    # Put the dimensions of input_shifted in a 1d array\n",
    "    Dimensions = np.asarray(input_shifted.shape)\n",
    "\n",
    "    # how many things in the first dimension of input_shifted\n",
    "    n = Dimensions[0]\n",
    "\n",
    "    # get the dimensionality (eg. 2d, 3d etc) of input_shifted\n",
    "    dn = input_shifted.ndim\n",
    "\n",
    "    # creates a vector [1,...,n], the same length as the first dimension of input_shifted\n",
    "    Freq = np.arange(1.0, n + 1)\n",
    "\n",
    "    # Equivalent in python: Freq = (Freq-1)/n*samplingRate\n",
    "    Freq = Freq / n * samplingRate\n",
    "\n",
    "    # Create boolean mask same size as Freq, true in between the frequency limits wl,wh\n",
    "    mask = (Freq > wl) & (Freq < wh)\n",
    "\n",
    "    Dimensions[0] = 1\n",
    "    mask = repmat(mask, np.ndarray(Dimensions))\n",
    "\n",
    "    # F = fft(X,[],dim) and F = fft(X,n,dim) applies the FFT operation across the dimension dim.\n",
    "    # Python: F = np.fftn(a=input_shifted,axes=0)\n",
    "    F = np.fft.fftn(a=input_shifted, axes=[0])\n",
    "\n",
    "    # So we are indexing array F using boolean not mask, and setting those values of F to zero, so the others pass thru\n",
    "    # Python: F[ np.logical_not(mask) ]\n",
    "    F[np.logical_not(mask)] = 0\n",
    "\n",
    "    # Get the real part of the inverse fourier transform of the filtered input\n",
    "    filtered = np.fft.ifftn(a=F, axes=[0]).real\n",
    "\n",
    "    filtered = filtered.astype(np.float32)\n",
    "\n",
    "    filtered = shiftdim(filtered, dn - (dim - 1))\n",
    "\n",
    "    return filtered\n",
    "#\n",
    "# def ideal_bandpassing(input, dim, wl, wh, fs):\n",
    "#     if dim > np.asarray(input.shape).ndim:\n",
    "#         print('Exceed maximum dimension')\n",
    "#     input_shifted = shiftdim(input, dim - 1)  # need to implement shift_dim\n",
    "#     dimension = np.asarray(input_shifted.shape)\n",
    "#\n",
    "#     n = dimension[0]\n",
    "#     dn = input_shifted.ndim\n",
    "#\n",
    "#     Freq = np.arange(n)\n",
    "#     Freq = Freq / n * fs  # removed minus 1 because the array start at 0 and matlab starts at 1 so in matalb yousould subtract by 1\n",
    "#     mask = (Freq > wl) & (Freq < wh)\n",
    "#     dimension[0] = 1\n",
    "#     mask = mask.flatten('F')\n",
    "#     # tmp = repmat(mask,dimension)\n",
    "#     mask = np.tile(mask, np.ndarray(dimension))\n",
    "#     F = np.fft.fft(input_shifted, axis=0)\n",
    "#     mask.resize(F.shape)\n",
    "#     F[~mask] = 0  # dont know what is this\n",
    "#\n",
    "#     filtered = np.fft.ifft(a=F, axis=0).real\n",
    "#     filtered = filtered.astype(np.float32)\n",
    "#\n",
    "#     filtered = shiftdim(filtered, dn - (dim - 1))\n",
    "#\n",
    "#     return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### build_gdown_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_gdown_stack(vid_file, start_index, end_index, level):\n",
    "    vid = cv2.VideoCapture(vid_file)\n",
    "    vid_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    vid_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    n_channels = 3\n",
    "\n",
    "    suc, temp = vid.read()\n",
    "    temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    # frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)  # im2double\n",
    "    frame = im2double(temp)\n",
    "    frame = color.rgb2yiq(frame)\n",
    "    # frame = rgb2ntsc(frame)\n",
    "\n",
    "    blurred = blur_dn_clr(frame, level)  # need to implement this\n",
    "\n",
    "    gdown_stack = np.zeros((end_index - start_index + 1, blurred.shape[0], blurred.shape[1], blurred.shape[2]))\n",
    "    gdown_stack[0, :, :, :] = blurred\n",
    "\n",
    "    for k in range(start_index, end_index + 1):\n",
    "        succ, temp = vid.read()\n",
    "        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "        frame = im2double(temp)\n",
    "        # frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)  # im2double\n",
    "        # frame = rgb2ntsc(frame)\n",
    "        frame = color.rgb2yiq(frame)\n",
    "        blurred = blur_dn_clr(frame, level)\n",
    "        gdown_stack[k, :, :, :] = blurred\n",
    "\n",
    "    return gdown_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### amplify_spatial_Gdown_temporal_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def im2double(im):\n",
    "    info = np.iinfo(im.dtype)  # Get the data type of the input image\n",
    "    return im.astype(np.float) / info.max  # Divide all values by the largest possible value in the datatype\n",
    "\n",
    "\n",
    "def amplify_spatial_Gdown_temporal_ideal(vid_file, out_file, alpha, level, fl, fh, fs, chrom_attenuation):\n",
    "    out_name = \"out2.avi\"\n",
    "    vid = cv2.VideoCapture(vid_file)\n",
    "    fr = vid.get(cv2.CAP_PROP_FPS)\n",
    "    len_ = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    vid_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    vid_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    start_index = 0\n",
    "    end_index = len_ - 10\n",
    "\n",
    "    cap_size = (vid_width, vid_height)  # this is the size of my source video\n",
    "    vid_out = cv2.VideoWriter()\n",
    "    fourcc = vid_out.fourcc('j', 'p', 'e', 'g')  # note the lower case\n",
    "    success = vid_out.open(out_name, fourcc, fr, cap_size, True)\n",
    "\n",
    "    logging.info('Spatial filtering...')\n",
    "    gdown_stack = build_gdown_stack(vid_file, start_index, end_index, level)\n",
    "    logging.info('Finished')\n",
    "\n",
    "    logging.info('Temporal filtering...')\n",
    "    filtered_stack = ideal_bandpassing(gdown_stack, 1, fl, fh, fs)\n",
    "    logging.info('Finished')\n",
    "\n",
    "    # amplify\n",
    "    filtered_stack[:, :, :, 0] = filtered_stack[:, :, :, 0] * alpha\n",
    "    filtered_stack[:, :, :, 1] = filtered_stack[:, :, :, 1] * alpha * chrom_attenuation\n",
    "    filtered_stack[:, :, :, 2] = filtered_stack[:, :, :, 2] * alpha * chrom_attenuation\n",
    "\n",
    "    logging.info('Rendering...')\n",
    "\n",
    "    for k in range(start_index, end_index + 1):\n",
    "        succ, temp = vid.read()\n",
    "        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "        # frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)  # im2double\n",
    "        frame = im2double(temp)\n",
    "        frame = color.rgb2yiq(frame)\n",
    "        filtered = (filtered_stack[k, :, :, :]).squeeze()\n",
    "        filtered = cv2.resize(filtered, (vid_width, vid_height), 0, 0, cv2.INTER_LINEAR)\n",
    "        filtered = filtered + frame\n",
    "        frame = color.yiq2rgb(filtered)\n",
    "        frame *= 255\n",
    "        frame = np.clip(frame, 0, 255)\n",
    "        frame = cv2.convertScaleAbs(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        vid_out.write(frame)\n",
    "\n",
    "    logging.info('Finished')\n",
    "    vid_out.release()\n",
    "    vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "def binomial_filter(sz):\n",
    "    if sz < 2:\n",
    "        logging.warning('size argument must be larger than 1')\n",
    "    kernel = [0.5, 0.5]\n",
    "    for n in range(0, sz - 2):\n",
    "        kernel = np.convolve([0.5, 0.5], kernel)\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def named_filter(name):\n",
    "    if name[:5] == 'binom':\n",
    "        kernel = np.sqrt(2) * binomial_filter(int(name[5:]))\n",
    "    elif name == 'qmf5':\n",
    "        kernel = np.asarray((-0.076103, 0.3535534, 0.8593118, 0.3535534, -0.076103))\n",
    "    elif name == 'qmf9':\n",
    "        kernel = np.asarray((0.02807382, -0.060944743, -0.073386624, 0.41472545, 0.7973934,\n",
    "                             0.41472545, -0.073386624, -0.060944743, 0.02807382))\n",
    "    elif name == 'qmf13':\n",
    "        kernel = np.asarray((-0.014556438, 0.021651438, 0.039045125, -0.09800052,\n",
    "                             -0.057827797, 0.42995453, 0.7737113, 0.42995453, -0.057827797,\n",
    "                             -0.09800052, 0.039045125, 0.021651438, -0.014556438))\n",
    "    elif name == 'qmf8':\n",
    "        kernel = np.sqrt(2) * np.asarray((0.00938715, -0.07065183, 0.06942827, 0.4899808,\n",
    "                                          0.4899808, 0.06942827, -0.07065183, 0.00938715))\n",
    "    elif name == 'qmf12':\n",
    "        kernel = np.sqrt(2) * np.asarray((-0.003809699, 0.01885659, -0.002710326, -0.08469594,\n",
    "                                          0.08846992, 0.4843894, 0.4843894, 0.08846992, -0.08469594, -0.002710326,\n",
    "                                          0.01885659, -0.003809699))\n",
    "    elif name == 'qmf16':\n",
    "        kernel = np.sqrt(2) * np.asarray((0.001050167, -0.005054526, -0.002589756, 0.0276414, -0.009666376,\n",
    "                                          -0.09039223, 0.09779817, 0.4810284, 0.4810284, 0.09779817, -0.09039223,\n",
    "                                          -0.009666376,\n",
    "                                          0.0276414, -0.002589756, -0.005054526, 0.001050167))\n",
    "    elif name == 'haar':\n",
    "        kernel = np.asarray((1, 1)) / np.sqrt(2)\n",
    "    elif name == 'daub2':\n",
    "        kernel = np.asarray((0.482962913145, 0.836516303738, 0.224143868042, -0.129409522551))\n",
    "    elif name == 'daub3':\n",
    "        kernel = np.asarray((0.332670552950, 0.806891509311, 0.459877502118, -0.135011020010,\n",
    "                             -0.085441273882, 0.035226291882))\n",
    "    elif name == 'daub4':\n",
    "        kernel = np.asarray((0.230377813309, 0.714846570553, 0.630880767930, -0.027983769417,\n",
    "                             -0.187034811719, 0.030841381836, 0.032883011667, -0.010597401785))\n",
    "    elif name == 'gauss5':  # for backward-compatibility\n",
    "        kernel = np.sqrt(2) * np.asarray((0.0625, 0.25, 0.375, 0.25, 0.0625))\n",
    "    elif name == 'gauss3':  # for backward-compatibility\n",
    "        kernel = np.sqrt(2) * np.asarray((0.25, 0.5, 0.25))\n",
    "    else:\n",
    "        logging.warning('Bad filter name: ', name)\n",
    "        return\n",
    "\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def parse_filter(filt, normalize=True):\n",
    "    if isinstance(filt, str):\n",
    "        filt = named_filter(filt)\n",
    "\n",
    "    elif isinstance(filt, np.ndarray) or isinstance(filt, list) or isinstance(filt, tuple):\n",
    "        filt = np.array(filt)\n",
    "        if filt.ndim == 1:\n",
    "            filt = np.reshape(filt, (filt.shape[0], 1))\n",
    "        elif filt.ndim == 2 and filt.shape[0] == 1:\n",
    "            filt = np.reshape(filt, (-1, 1))\n",
    "\n",
    "    # TODO expand normalization options\n",
    "    if normalize:\n",
    "        filt = filt / filt.sum()\n",
    "\n",
    "    return filt\n",
    "\n",
    "\n",
    "# def blur_dn(image, n_levels=1, filt='binom5'):\n",
    "#     if image.ndim == 1:\n",
    "#         image = image.reshape(-1, 1)\n",
    "#\n",
    "#     filt = parse_filter(filt)\n",
    "#     filt = filt / np.sum(filt.flatten('F'))  # normalize\n",
    "#     if n_levels > 1:\n",
    "#         image = blur_dn(image, n_levels - 1, filt)\n",
    "#\n",
    "#     if n_levels >= 1:\n",
    "#         if image.shape[1] == 1:\n",
    "#             # 1D image [M, 1] and 1D filter [N, 1]\n",
    "#             res = corr_dn(image=image, filt=filt, step=(2, 1))\n",
    "#\n",
    "#         elif image.shape[0] == 1:\n",
    "#             # 1D image [1, M] and 1D filter [N, 1]\n",
    "#             res = corr_dn(image=image, filt=filt.T, step=(1, 2))\n",
    "#\n",
    "#         elif filt.shape[1] == 1:\n",
    "#             # 2D image and 1D filter [N, 1]\n",
    "#             res = corr_dn(image=image, filt=filt, step=(2, 1))\n",
    "#             res = corr_dn(image=res, filt=filt.T, step=(1, 2))\n",
    "#\n",
    "#         else:\n",
    "#             # 2D image and 2D filter\n",
    "#             res = corr_dn(image=image, filt=filt, step=(2, 2))\n",
    "#\n",
    "#     else:\n",
    "#         res = image\n",
    "#\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "def blur_dn(im, nlevs=1, filt='binom5'):\n",
    "    if type(filt) == str:\n",
    "        filt = named_filter(filt)\n",
    "    filt = filt / np.sum(filt.flatten('F'))\n",
    "    if nlevs > 1:\n",
    "        im = blur_dn(im, nlevs - 1, filt)\n",
    "\n",
    "    if nlevs >= 1:\n",
    "        if np.asarray(im.shape).ndim == 1:\n",
    "            if np.asarray(filt.shape).ndim != 1:\n",
    "                logging.warning('Cant apply 2D filter to 1D signal')\n",
    "                return\n",
    "            if im.ndim == 1:\n",
    "                filt = filt.flatten('F')\n",
    "            else:\n",
    "                filt = filt.flatten('F')\n",
    "                filt = np.conjugate(filt).T\n",
    "                filt = filt.reshape(-1, 1)\n",
    "            res = corr_dn(im, filt, 'reflect1', tuple(map(lambda x: int(not x == 1) + 1, im.shape)))\n",
    "        elif np.asarray(filt.shape).ndim == 1:\n",
    "            filt = filt.flatten(\"F\")\n",
    "            res = corr_dn(im, filt, 'reflect1', (2, 1))\n",
    "            res = corr_dn(res, filt, 'reflect1', (1, 2))\n",
    "        else:\n",
    "            res = corr_dn(im, filt, 'reflect1', (2, 2))\n",
    "    else:\n",
    "        res = im\n",
    "    return res\n",
    "\n",
    "\n",
    "def blur_dn_clr(im, n_levs=1, filt='binom5'):\n",
    "    # tmp = pt.blurDn(im[:,:,0],nlevs,filt)\n",
    "    # tmp = pt.blurDn(im[:, :, 0].copy(), n_levs, filt)\n",
    "    tmp = blur_dn(im[:, :, 0].copy(), n_levs, filt)\n",
    "    out = np.zeros((tmp.shape[0], tmp.shape[1], im.shape[2]))\n",
    "    out[:, :, 0] = tmp\n",
    "    for clr in range(1, im.shape[2]):\n",
    "        # out[:, :, clr] = pt.blur_dn(im[:, :, clr], n_levs, filt)\n",
    "        out[:, :, clr] = blur_dn(im[:, :, clr], n_levs, filt)\n",
    "    return out\n",
    "\n",
    "\n",
    "# def corr_dn(nhls, phls, nrhs, prhs):\n",
    "#     logging.info(\"Parameters received:\\n\" + str(nhls) + \"\\n\" + str(phls) +\n",
    "#                  \"\\n\" + str(nrhs) + \"\\n\" + str(prhs))\n",
    "#     x_start = 1\n",
    "#     x_step = 1\n",
    "#     y_start = 1\n",
    "#     y_step = 1\n",
    "#\n",
    "#     edges = 'reflect1'\n",
    "#     edges = 'reflect1'\n",
    "#\n",
    "#     logging.info(prhs[0])\n",
    "#     arg0 = prhs[0]\n",
    "#     image = arg0\n",
    "#     x_idim = int(arg0.shape[0])\n",
    "#     y_idim = int(arg0.shape[1])\n",
    "#\n",
    "#     arg1 = prhs[1]\n",
    "#     flit = arg1.data\n",
    "#     x_fdim = int(arg1.shape[0])\n",
    "#     y_fdim = int(arg1.shape[1])\n",
    "#\n",
    "#     x_start -= 1\n",
    "#     y_start -= 1\n",
    "#\n",
    "#     x_rdim = (x_stop-x_start+x_step-1) / x_step\n",
    "#     y_rdim = (y_stop-y_start+y_step-1) / y_step\n",
    "#\n",
    "#     plhs[0] = np.zeros((x_rdim, y_rdim))\n",
    "#     result = plhs[0]\n",
    "#\n",
    "#     if edges == \"circular\":\n",
    "#         pt.internal_wrap_reduce(image, x_idim, y_idim, flit, x_fdim, y_fdim,\n",
    "#                x_start, x_step, y_start, y_step,\n",
    "#                result)\n",
    "#     else:\n",
    "#         pt.internal_reduce(image, x_idim, y_idim, flit, x_fdim, y_fdim,\n",
    "#                x_start, x_step, y_start, y_step,\n",
    "#                result)\n",
    "#     return result\n",
    "\n",
    "# def corr_dn(im,file,edges,step = [1,1],start = [1,1]):\n",
    "#     stop = len(im)\n",
    "#     filt = filt[filt.shape[0]:-1:0,filt.shape[1]:-1:0]\n",
    "#     temp = rconv2(im,filt)\n",
    "#\n",
    "#     res = tmp[start[0]:step[0]:stop[0],start[1]:step[1]:stop[1]]\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corr down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "def corr_dn(image, filt, edge_type='reflect1', step=(1, 1), start=(0, 0),\n",
    "            stop=None):\n",
    "    image = image.copy().astype(float)\n",
    "    filt = filt.copy().astype(float)\n",
    "\n",
    "    if image.shape[0] < filt.shape[0] or image.shape[1] < filt.shape[1]:\n",
    "        raise Exception(\"Signal smaller than filter in corresponding dimension: \", image.shape, filt.shape,\n",
    "                        \" see parse filter\")\n",
    "\n",
    "    if edge_type not in ['circular', 'reflect1', 'reflect2', 'repeat', 'zero', 'extend', 'dont-compute']:\n",
    "        raise Exception(\"Don't know how to do convolution with edge_type %s!\" % edge_type)\n",
    "\n",
    "    if filt.ndim == 1:\n",
    "        filt = filt.reshape(1, -1)\n",
    "\n",
    "    if stop is None:\n",
    "        stop = (image.shape[0], image.shape[1])\n",
    "\n",
    "    rxsz = len(range(start[0], stop[0], step[0]))\n",
    "    rysz = len(range(start[1], stop[1], step[1]))\n",
    "    result = np.zeros((rxsz, rysz))\n",
    "\n",
    "    if edge_type == 'circular':\n",
    "        lib.internal_wrap_reduce(image.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                                 image.shape[1], image.shape[0],\n",
    "                                 filt.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                                 filt.shape[1], filt.shape[0],\n",
    "                                 start[1], step[1], stop[1], start[0], step[0],\n",
    "                                 stop[0],\n",
    "                                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double)))\n",
    "    else:\n",
    "        tmp = np.zeros((filt.shape[0], filt.shape[1]))\n",
    "        lib.internal_reduce(image.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            image.shape[1], image.shape[0],\n",
    "                            filt.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            tmp.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            filt.shape[1], filt.shape[0],\n",
    "                            start[1], step[1], stop[1], start[0], step[0],\n",
    "                            stop[0],\n",
    "                            result.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            edge_type.encode('ascii'))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def reconv2(a, b, ctr):\n",
    "    if len(a[1]) >= len(b[1]) and len(a[2]) >= len(b[2]):\n",
    "        large = a\n",
    "        small = b\n",
    "    elif len(a[1]) <= len(b[1]) and len(a[2]) <= len(b[2]):\n",
    "        large = b\n",
    "        small = a\n",
    "    else:\n",
    "        raise Exception(\"one arg must be larger than the other in both dimensions!\")\n",
    "\n",
    "    ly = len(large[1])\n",
    "    lx = len(large[2])\n",
    "    sy = len(small[1])\n",
    "    sx = len(small[2])\n",
    "\n",
    "    \"\"\"\n",
    "    These values are one less than the index of the small mtx that falls on\n",
    "    the border pixel of the large matrix when computing the first\n",
    "    convolution response sample:\n",
    "    \"\"\"\n",
    "    sy2 = math.floor((sy + ctr - 1) / 2)\n",
    "    sx2 = math.floor((sx + ctr - 1) / 2)\n",
    "\n",
    "    # pad with reflected copies\n",
    "    clarge = np.asarray(np.block(large[sy - sy2:-1:2, sx - sx2:-1:2], large[sy - sy2:-1:2, :],\n",
    "                                 large[sy - sy2:-1:2, lx - 1:-1:lx - sx2]),\n",
    "                        np.block(large[:, sx - sx2:-1:2], large, large[:, lx - 1:-1:lx - sx2]),\n",
    "                        np.block(large[ly - 1:-1:ly - sy2, sx - sx2:-1:2], large[ly - 1:-1:ly - sy2, :],\n",
    "                                 large[ly - 1:-1:ly - sy2, lx - 1:-1:lx - sx2]))\n",
    "\n",
    "    c = scipy.signal.convolve2d(clarge, small, boundary='valid', mode='same')\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "FORMAT = '[%(asctime)s] [%(levelname)s] [%(funcName)s] [%(lineno)d] : %(message)s'\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "logging.info(\"Starting ...\")\n",
    "if platform.system() == \"Windows\":\n",
    "    seperator = \"\\\\\"\n",
    "else:\n",
    "    seperator = \"/\"\n",
    "\n",
    "dir = \"perry-all-2\"\n",
    "# should be a parameter of the engine\n",
    "dataset_location = \"..\" + seperator + \"dataset\" + seperator + \"good_sync\" + seperator\n",
    "specific_dir = dir\n",
    "#video_location = dataset_location + specific_dir + seperator + \"test1.mp4\"\n",
    "video_location = \"rotated.mp4\"\n",
    "\n",
    "if platform.system() == \"Linux\":\n",
    "    libpath = \"/home/eyalgolan/PycharmProjects/KOIOS/venv/lib/python3.8/site-packages/wrapConv.cpython-38-x86_64-linux-gnu.so\"\n",
    "elif platform.system()  == \"Darwin\":\n",
    "    libpath = \"wrapConv.cpython-38-darwin.so\"\n",
    "else:\n",
    "    logging.error(\"Unsupported OS, please run on Linux or Mac!\")\n",
    "\n",
    "#libpath = \"/home/eyalgolan/PycharmProjects/KOIOS/wrapConv.cpython-38-x86_64-linux-gnu.so\"\n",
    "logging.info(\"libpath:\" + str(libpath))\n",
    "\n",
    "# load the c library\n",
    "if len(libpath) > 0:\n",
    "    lib = ctypes.cdll.LoadLibrary(libpath)\n",
    "else:\n",
    "    logging.error(\"Can't load in C code, something went wrong in your install!\")\n",
    "\n",
    "# hpyer params here were taken from the matlab implementation but might need to be changed (there were several options and I took the face option)\n",
    "amplify_spatial_Gdown_temporal_ideal(video_location, \"/\", 50, 4, 50 / 60, 60 / 60, 30, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
