{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pyrtools as pt\n",
    "import logging\n",
    "import platform\n",
    "import glob\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def amplify_spatial_Gdown_temporal_ideal(vid_file,out_file,alpha,level,fl,fh,fs,chrom_attenuation):\n",
    "    out_name = \"out.avi\"\n",
    "    vid = cv2.VideoCapture(vid_file)\n",
    "    fr = vid.get(cv2.CAP_PROP_FPS)\n",
    "    len_ = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    vid_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    vid_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    start_index = 0\n",
    "    end_index = len_-10\n",
    "\n",
    "    cap_size = (vid_width, vid_height)  # this is the size of my source video\n",
    "    vid_out = cv2.VideoWriter()\n",
    "    fourcc = vid_out.fourcc('j', 'p', 'e', 'g')  # note the lower case\n",
    "    success = vid_out.open(out_name, fourcc, fr, cap_size, True)\n",
    "\n",
    "    logging.info('Spatial filtering...')\n",
    "    gdown_stack = build_gdown_stack(vid_file,start_index,end_index,level)\n",
    "    logging.info('Finished')\n",
    "\n",
    "    logging.info('Temporal filtering...')\n",
    "    filtered_stack = ideal_bandpassing(gdown_stack,1,fl,fh,fs)\n",
    "    logging.info('Finished')\n",
    "\n",
    "    #amplify\n",
    "    filtered_stack[:,:,:,0] = filtered_stack[:,:,:,0] * alpha\n",
    "    filtered_stack[:,:,:,1] = filtered_stack[:,:,:,1] * alpha * chrom_attenuation\n",
    "    filtered_stack[:,:,:,2] = filtered_stack[:,:,:,2] * alpha * chrom_attenuation\n",
    "\n",
    "    logging.info('Rendering...')\n",
    "\n",
    "    for k in range(start_index,end_index+1):\n",
    "        succ,temp = vid.read()\n",
    "\n",
    "        frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX) # im2double\n",
    "        frame = rgb2ntsc(frame)\n",
    "\n",
    "        filtered = np.squeeze(filtered_stack[k, :, :, :])\n",
    "        filtered = cv2.resize(filtered, (vidWidth, vidHeight), 0, 0, cv2.INTER_LINEAR)\n",
    "\n",
    "        filtered = filtered + frame\n",
    "\n",
    "        frame = ntsc2rgb(filtered)\n",
    "\n",
    "        frame = np.clip(frame, 0, 255)\n",
    "        frame = cv2.convertScaleAbs(frame)\n",
    "\n",
    "        vid_out.write(frame)\n",
    "\n",
    "\n",
    "    logging.info('Finished')\n",
    "    vid_out.release()\n",
    "    vid.release()\n",
    "\n",
    "def rgb2ntsc(frame):\n",
    "    YIQ = np.ndarray(frame.shape)\n",
    "\n",
    "    YIQ[:, :, 0] = 0.299 * frame[:, :, 0] + 0.587 * frame[:, :, 1] + 0.114 * frame[:, :, 2]\n",
    "    YIQ[:, :, 1] = 0.59590059 * frame[:, :, 0] + (-0.27455667) * frame[:, :, 1] + (-0.32134392) * frame[:, :, 2]\n",
    "    YIQ[:, :, 2] = 0.21153661 * frame[:, :, 0] + (-0.52273617) * frame[:, :, 1] + 0.31119955 * frame[:, :, 2]\n",
    "    return YIQ\n",
    "\n",
    "\n",
    "def ntsc2rgb(frame):\n",
    "    RGB = np.ndarray(frame.shape)\n",
    "    RGB[:, :, 0] = 1.00000001 * frame[:, :, 0] + 0.95598634 * frame[:, :, 1] + 0.6208248 * frame[:, :, 2]\n",
    "    RGB[:, :, 1] = 0.99999999 * frame[:, :, 0] + (-0.27201283) * frame[:, :, 1] + (-0.64720424) * frame[:, :, 2]\n",
    "    RGB[:, :, 2] = 1.00000002 * frame[:, :, 0] + (-1.10674021) * frame[:, :, 1] + 1.70423049 * frame[:, :, 2]\n",
    "    return RGB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def binomial_filter(sz):\n",
    "    if sz < 2:\n",
    "        logging.warning('size argument must be larger than 1')\n",
    "    kernel = [0.5,0.5]\n",
    "    for n in range(0,sz-2):\n",
    "        kernel = np.convolve([0.5,0.5],kernel)\n",
    "    return kernel\n",
    "\n",
    "def named_filter(name):\n",
    "    if name[:5] == 'binom':\n",
    "        kernel = np.sqrt(2) * binomial_filter(int(name[5:]))\n",
    "    elif name == 'qmf5':\n",
    "        kernel = np.asarray((-0.076103, 0.3535534, 0.8593118, 0.3535534, -0.076103))\n",
    "    elif name == 'qmf9':\n",
    "        kernel = np.asarray((0.02807382, -0.060944743, -0.073386624, 0.41472545, 0.7973934,\n",
    "                             0.41472545, -0.073386624, -0.060944743, 0.02807382))\n",
    "    elif name == 'qmf13':\n",
    "        kernel = np.asarray((-0.014556438, 0.021651438, 0.039045125, -0.09800052,\n",
    "                             -0.057827797, 0.42995453, 0.7737113, 0.42995453, -0.057827797,\n",
    "                             -0.09800052, 0.039045125, 0.021651438, -0.014556438))\n",
    "    elif name == 'qmf8':\n",
    "        kernel = np.sqrt(2) * np.asarray((0.00938715, -0.07065183, 0.06942827, 0.4899808,\n",
    "                                          0.4899808, 0.06942827, -0.07065183, 0.00938715))\n",
    "    elif name == 'qmf12':\n",
    "        kernel = np.sqrt(2) * np.asarray((-0.003809699, 0.01885659, -0.002710326, -0.08469594,\n",
    "                                          0.08846992, 0.4843894, 0.4843894, 0.08846992, -0.08469594, -0.002710326,\n",
    "                                          0.01885659, -0.003809699))\n",
    "    elif name == 'qmf16':\n",
    "        kernel = np.sqrt(2) * np.asarray((0.001050167, -0.005054526, -0.002589756, 0.0276414, -0.009666376,\n",
    "                                          -0.09039223, 0.09779817, 0.4810284, 0.4810284, 0.09779817, -0.09039223,\n",
    "                                          -0.009666376,\n",
    "                                          0.0276414, -0.002589756, -0.005054526, 0.001050167))\n",
    "    elif name == 'haar':\n",
    "        kernel = np.asarray((1, 1)) / np.sqrt(2)\n",
    "    elif name == 'daub2':\n",
    "        kernel = np.asarray((0.482962913145, 0.836516303738, 0.224143868042, -0.129409522551))\n",
    "    elif name == 'daub3':\n",
    "        kernel = np.asarray((0.332670552950, 0.806891509311, 0.459877502118, -0.135011020010,\n",
    "                             -0.085441273882, 0.035226291882))\n",
    "    elif name == 'daub4':\n",
    "        kernel = np.asarray((0.230377813309, 0.714846570553, 0.630880767930, -0.027983769417,\n",
    "                             -0.187034811719, 0.030841381836, 0.032883011667, -0.010597401785))\n",
    "    elif name == 'gauss5':  # for backward-compatibility\n",
    "        kernel = np.sqrt(2) * np.asarray((0.0625, 0.25, 0.375, 0.25, 0.0625))\n",
    "    elif name == 'gauss3':  # for backward-compatibility\n",
    "        kernel = np.sqrt(2) * np.asarray((0.25, 0.5, 0.25))\n",
    "    else:\n",
    "        logging.warning('Bad filter name: ', name)\n",
    "        return\n",
    "\n",
    "    return kernel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def parse_filter(filt, normalize=True):\n",
    "    if isinstance(filt, str):\n",
    "        filt = named_filter(filt)\n",
    "\n",
    "    elif isinstance(filt, np.ndarray) or isinstance(filt, list) or isinstance(filt, tuple):\n",
    "        filt = np.array(filt)\n",
    "        if filt.ndim == 1:\n",
    "            filt = np.reshape(filt, (filt.shape[0], 1))\n",
    "        elif filt.ndim == 2 and filt.shape[0] == 1:\n",
    "            filt = np.reshape(filt, (-1, 1))\n",
    "\n",
    "    # TODO expand normalization options\n",
    "    if normalize:\n",
    "        filt = filt / filt.sum()\n",
    "\n",
    "    return filt\n",
    "\n",
    "def blur_dn(image, n_levels=1, filt='binom5'):\n",
    "    if image.ndim == 1:\n",
    "        image = image.reshape(-1, 1)\n",
    "\n",
    "    filt = parse_filter(filt)\n",
    "\n",
    "    if n_levels > 1:\n",
    "        image = blur_dn(image, n_levels-1, filt)\n",
    "\n",
    "    if n_levels >= 1:\n",
    "        if image.shape[1] == 1:\n",
    "            # 1D image [M, 1] and 1D filter [N, 1]\n",
    "            res = corr_dn(image=image, filt=filt, step=(2, 1))\n",
    "\n",
    "        elif image.shape[0] == 1:\n",
    "            # 1D image [1, M] and 1D filter [N, 1]\n",
    "            res = corr_dn(image=image, filt=filt.T, step=(1, 2))\n",
    "\n",
    "        elif filt.shape[1] == 1:\n",
    "            # 2D image and 1D filter [N, 1]\n",
    "            res = corr_dn(image=image, filt=filt, step=(2, 1))\n",
    "            res = corr_dn(image=res, filt=filt.T, step=(1, 2))\n",
    "\n",
    "        else:\n",
    "            # 2D image and 2D filter\n",
    "            res = corr_dn(image=image, filt=filt, step=(2, 2))\n",
    "\n",
    "    else:\n",
    "        res = image\n",
    "\n",
    "    return res\n",
    "\n",
    "# def blur_dn(im,nlevs = 1,filt = 'binom5'):\n",
    "#     if type(filt) == str:\n",
    "#         filt = named_filter(filt)\n",
    "#     filt = filt/ np.sum(filt.flatten('F'))\n",
    "#\n",
    "#     if nlevs > 1:\n",
    "#         im = blur_dn(im,nlevs-1,filt)\n",
    "#\n",
    "#     if nlevs>=1:\n",
    "#         if np.any(np.shape(im) ==1):\n",
    "#             if ~np.any(np.shape(filt) == 1):\n",
    "#                 logging.warning('Cant apply 2D filter to 1D signal')\n",
    "#                 return\n",
    "#             if im.shape[1] == 1:\n",
    "#                 filt = filt.flatten('F')\n",
    "#             else:\n",
    "#                 filt =filt.flatten('F').H\n",
    "#             arr = np.asarray(im.shape)\n",
    "#             for i in arr:\n",
    "#                 arr[i] = int(np.logical_not(arr[i],1))\n",
    "#             arr = arr +1\n",
    "#             res = corr_dn(im,filt,'reflect1',arr)\n",
    "#         elif np.any(np.shape(filt) == 1):\n",
    "#             filt = filt.flatten(\"F\")\n",
    "#             res = corr_dn(im,filt,'reflect1',[2,1])\n",
    "#             res = corr_dn(res,filt,'reflect1',[1,2])\n",
    "#         else:\n",
    "#             res = corr_dn(im,filt,'reflect1',[2,2])\n",
    "#     else:\n",
    "#         res = im\n",
    "#     return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def blur_dn_clr(im,nlevels=1,filt='binom5'):\n",
    "    #tmp = pt.blurDn(im[:,:,0],nlevels,filt)\n",
    "    tmp = blur_dn(im[:,:,0],nlevels,filt)\n",
    "    out = np.zeros(tmp.shape[0],temp.shape[1],im.shape[2])\n",
    "    out[:,:,0] = tmp\n",
    "    for clr in range(1, im.shape[2]):\n",
    "        #out[:, :, clr] = pt.blur_dn(im[:, :, clr], nlevs, filt)\n",
    "        out[:, :, clr] = blur_dn(im[:, :, clr], nlevs, filt)\n",
    "\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def build_gdown_stack(vid_file,start_index,end_index,level):\n",
    "\n",
    "    vid = cv2.VideoCapture(vid_file)\n",
    "    vid_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    vid_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    n_channels = 3\n",
    "\n",
    "    suc,temp = vid.read()\n",
    "    frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX) # im2double\n",
    "    frame = rgb2ntsc(frame)\n",
    "\n",
    "    blurred = blur_dn_clr(frame,level) # need to implement this\n",
    "\n",
    "    gdown_stack = np.zeros(end_index - start_index +1, blurred.shape[0],blurred.shape[1],blurred.shape[2])\n",
    "    gdown_stack[0,:,:,:] = blurred\n",
    "\n",
    "    for k in range(start_index,end_index+1):\n",
    "\n",
    "\n",
    "        succ,temp = vid.read()\n",
    "\n",
    "        frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX) # im2double\n",
    "        frame = rgb2ntsc(frame)\n",
    "        blurred = blue_dn_clr(frame,level)\n",
    "        gdown_stack[k,:,:,:] = blurred\n",
    "\n",
    "    return gdown_stack\n",
    "\n",
    "def rgb2ntsc(frame):\n",
    "    YIQ = np.ndarray(frame.shape)\n",
    "\n",
    "    YIQ[:, :, 0] = 0.299 * frame[:, :, 0] + 0.587 * frame[:, :, 1] + 0.114 * frame[:, :, 2]\n",
    "    YIQ[:, :, 1] = 0.59590059 * frame[:, :, 0] + (-0.27455667) * frame[:, :, 1] + (-0.32134392) * frame[:, :, 2]\n",
    "    YIQ[:, :, 2] = 0.21153661 * frame[:, :, 0] + (-0.52273617) * frame[:, :, 1] + 0.31119955 * frame[:, :, 2]\n",
    "    return YIQ\n",
    "\n",
    "\n",
    "def ntsc2rgb(frame):\n",
    "    RGB = np.ndarray(frame.shape)\n",
    "    RGB[:, :, 0] = 1.00000001 * frame[:, :, 0] + 0.95598634 * frame[:, :, 1] + 0.6208248 * frame[:, :, 2]\n",
    "    RGB[:, :, 1] = 0.99999999 * frame[:, :, 0] + (-0.27201283) * frame[:, :, 1] + (-0.64720424) * frame[:, :, 2]\n",
    "    RGB[:, :, 2] = 1.00000002 * frame[:, :, 0] + (-1.10674021) * frame[:, :, 1] + 1.70423049 * frame[:, :, 2]\n",
    "    return RGB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# def corr_dn(nhls, phls, nrhs, prhs):\n",
    "#     logging.info(\"Parameters received:\\n\" + str(nhls) + \"\\n\" + str(phls) +\n",
    "#                  \"\\n\" + str(nrhs) + \"\\n\" + str(prhs))\n",
    "#     x_start = 1\n",
    "#     x_step = 1\n",
    "#     y_start = 1\n",
    "#     y_step = 1\n",
    "#\n",
    "#     edges = 'reflect1'\n",
    "#     edges = 'reflect1'\n",
    "#\n",
    "#     logging.info(prhs[0])\n",
    "#     arg0 = prhs[0]\n",
    "#     image = arg0\n",
    "#     x_idim = int(arg0.shape[0])\n",
    "#     y_idim = int(arg0.shape[1])\n",
    "#\n",
    "#     arg1 = prhs[1]\n",
    "#     flit = arg1.data\n",
    "#     x_fdim = int(arg1.shape[0])\n",
    "#     y_fdim = int(arg1.shape[1])\n",
    "#\n",
    "#     x_start -= 1\n",
    "#     y_start -= 1\n",
    "#\n",
    "#     x_rdim = (x_stop-x_start+x_step-1) / x_step\n",
    "#     y_rdim = (y_stop-y_start+y_step-1) / y_step\n",
    "#\n",
    "#     plhs[0] = np.zeros((x_rdim, y_rdim))\n",
    "#     result = plhs[0]\n",
    "#\n",
    "#     if edges == \"circular\":\n",
    "#         pt.internal_wrap_reduce(image, x_idim, y_idim, flit, x_fdim, y_fdim,\n",
    "#                x_start, x_step, y_start, y_step,\n",
    "#                result)\n",
    "#     else:\n",
    "#         pt.internal_reduce(image, x_idim, y_idim, flit, x_fdim, y_fdim,\n",
    "#                x_start, x_step, y_start, y_step,\n",
    "#                result)\n",
    "#     return result\n",
    "\n",
    "# def corr_dn(im,file,edges,step = [1,1],start = [1,1]):\n",
    "#     stop = len(im)\n",
    "#     filt = filt[filt.shape[0]:-1:0,filt.shape[1]:-1:0]\n",
    "#     temp = rconv2(im,filt)\n",
    "#\n",
    "#     res = tmp[start[0]:step[0]:stop[0],start[1]:step[1]:stop[1]]\n",
    "#     return res\n",
    "\n",
    "def corr_dn(image, filt, edge_type='reflect1', step=(1, 1), start=(0, 0),\n",
    "           stop=None):\n",
    "    image = image.copy().astype(float)\n",
    "    filt = filt.copy().astype(float)\n",
    "\n",
    "    if image.shape[0] < filt.shape[0] or image.shape[1] < filt.shape[1]:\n",
    "        raise Exception(\"Signal smaller than filter in corresponding dimension: \", image.shape, filt.shape, \" see parse filter\")\n",
    "\n",
    "    if edge_type not in ['circular', 'reflect1', 'reflect2', 'repeat', 'zero', 'extend', 'dont-compute']:\n",
    "        raise Exception(\"Don't know how to do convolution with edge_type %s!\" % edge_type)\n",
    "\n",
    "    if filt.ndim == 1:\n",
    "        filt = filt.reshape(1, -1)\n",
    "\n",
    "    if stop is None:\n",
    "        stop = (image.shape[0], image.shape[1])\n",
    "\n",
    "    rxsz = len(range(start[0], stop[0], step[0]))\n",
    "    rysz = len(range(start[1], stop[1], step[1]))\n",
    "    result = np.zeros((rxsz, rysz))\n",
    "\n",
    "    if edge_type == 'circular':\n",
    "        lib.internal_wrap_reduce(image.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                                 image.shape[1], image.shape[0],\n",
    "                                 filt.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                                 filt.shape[1], filt.shape[0],\n",
    "                                 start[1], step[1], stop[1], start[0], step[0],\n",
    "                                 stop[0],\n",
    "                                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double)))\n",
    "    else:\n",
    "        tmp = np.zeros((filt.shape[0], filt.shape[1]))\n",
    "        lib.internal_reduce(image.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            image.shape[1], image.shape[0],\n",
    "                            filt.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            tmp.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            filt.shape[1], filt.shape[0],\n",
    "                            start[1], step[1], stop[1], start[0], step[0],\n",
    "                            stop[0],\n",
    "                            result.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            edge_type.encode('ascii'))\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def reconv2(a,b,ctr):\n",
    "\tif len(a[1]) >= len(b[1]) and len(a[2]) >= len(b[2]):\n",
    "\t\tlarge = a\n",
    "\t\tsmall = b\n",
    "\telif len(a[1]) <= len(b[1]) and len(a[2]) <= len(b[2]):\n",
    "\t\tlarge = b\n",
    "\t\tsmall = a\n",
    "\telse:\n",
    "\t\traise Exception(\"one arg must be larger than the other in both dimensions!\")\n",
    "\n",
    "\tly = len(large[1])\n",
    "\tlx = len(large[2])\n",
    "\tsy = len(small[1])\n",
    "\tsx = len(small[2])\n",
    "\n",
    "\t\"\"\"\n",
    "\tThese values are one less than the index of the small mtx that falls on\n",
    "\tthe border pixel of the large matrix when computing the first\n",
    "\tconvolution response sample:\n",
    "\t\"\"\"\n",
    "\tsy2 = math.floor((sy+ctr-1)/2)\n",
    "\tsx2 = math.floor((sx+ctr-1)/2)\n",
    "\n",
    "\t# pad with reflected copies\n",
    "\tclarge = np.asarray(np.block(large[sy-sy2:-1:2,sx-sx2:-1:2], large[sy-sy2:-1:2,:], large[sy-sy2:-1:2,lx-1:-1:lx-sx2]),\n",
    "\tnp.block(large[:,sx-sx2:-1:2], large, large[:,lx-1:-1:lx-sx2]),\n",
    "\tnp.block(large[ly-1:-1:ly-sy2,sx-sx2:-1:2], large[ly-1:-1:ly-sy2,:], large[ly-1:-1:ly-sy2,lx-1:-1:lx-sx2]))\n",
    "\n",
    "\tc = signal.convolve2d(clarge, small, boundary='valid', mode='same')\n",
    "\n",
    "\treturn c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-30 19:29:20,019] [INFO] [<module>] [5] : Starting ...\n",
      "[2021-03-30 19:29:20,021] [WARNING] [<module>] [25] : Can't load in C code, something went wrong in your install!\n",
      "[2021-03-30 19:29:20,052] [INFO] [amplify_spatial_Gdown_temporal_ideal] [17] : Spatial filtering...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-63-930fe15e9fd8>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0;31m#hpyer params here were taken from the matlab implementation but might need to be changed (there were several options and I took the face option)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m \u001B[0mamplify_spatial_Gdown_temporal_ideal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvideo_location\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"/\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m50\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;36m60\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m60\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;36m60\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m30\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-56-b1328f828be7>\u001B[0m in \u001B[0;36mamplify_spatial_Gdown_temporal_ideal\u001B[0;34m(vid_file, out_file, alpha, level, fl, fh, fs, chrom_attenuation)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Spatial filtering...'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m     \u001B[0mgdown_stack\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbuild_gdown_stack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvid_file\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mstart_index\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mend_index\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m     \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Finished'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-60-8940c45470e2>\u001B[0m in \u001B[0;36mbuild_gdown_stack\u001B[0;34m(vid_file, start_index, end_index, level)\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrgb2ntsc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     \u001B[0mblurred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mblur_dn_clr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# need to implement this\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m     \u001B[0mgdown_stack\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mend_index\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart_index\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mblurred\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mblurred\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mblurred\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-59-b3eaa12b22f3>\u001B[0m in \u001B[0;36mblur_dn_clr\u001B[0;34m(im, nlevels, filt)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mblur_dn_clr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mim\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnlevels\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfilt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'binom5'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;31m#tmp = pt.blurDn(im[:,:,0],nlevels,filt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mtmp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mblur_dn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mim\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnlevels\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfilt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtmp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtemp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mout\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtmp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-58-3ff0b3b6e1b5>\u001B[0m in \u001B[0;36mblur_dn\u001B[0;34m(image, n_levels, filt)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mn_levels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mblur_dn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_levels\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mn_levels\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-58-3ff0b3b6e1b5>\u001B[0m in \u001B[0;36mblur_dn\u001B[0;34m(image, n_levels, filt)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mn_levels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mblur_dn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_levels\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mn_levels\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-58-3ff0b3b6e1b5>\u001B[0m in \u001B[0;36mblur_dn\u001B[0;34m(image, n_levels, filt)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mn_levels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mblur_dn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_levels\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mn_levels\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-58-3ff0b3b6e1b5>\u001B[0m in \u001B[0;36mblur_dn\u001B[0;34m(image, n_levels, filt)\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mfilt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m             \u001B[0;31m# 2D image and 1D filter [N, 1]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 39\u001B[0;31m             \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcorr_dn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfilt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     40\u001B[0m             \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcorr_dn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfilt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-61-1e0671e19f53>\u001B[0m in \u001B[0;36mcorr_dn\u001B[0;34m(image, filt, edge_type, step, start, stop)\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m         \u001B[0mtmp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 82\u001B[0;31m         lib.internal_reduce(image.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n\u001B[0m\u001B[1;32m     83\u001B[0m                             \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m                             \u001B[0mfilt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata_as\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPOINTER\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mc_double\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'lib' is not defined"
     ]
    }
   ],
   "source": [
    "FORMAT = '[%(asctime)s] [%(levelname)s] [%(funcName)s] [%(lineno)d] : %(message)s'\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "logging.info(\"Starting ...\")\n",
    "if platform.system() == \"Windows\":\n",
    "    seperator = \"\\\\\"\n",
    "else:\n",
    "    seperator = \"/\"\n",
    "\n",
    "dir = \"perry-all-2\"\n",
    "# should be a parameter of the engine\n",
    "dataset_location = \"..\" + seperator + \"dataset\" + seperator + \"good_sync\" + seperator\n",
    "specific_dir = dir\n",
    "video_location = dataset_location + specific_dir + seperator + \"test.mp4\"\n",
    "\n",
    "libpath = glob.glob(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'wrapConv*.so'))\n",
    "logging.info(\"libpath:\" + libpath)\n",
    "\n",
    "# load the c library\n",
    "if len(libpath) > 0:\n",
    "    lib = ctypes.cdll.LoadLibrary(libpath[0])\n",
    "else:\n",
    "    logging.warning(\"Can't load in C code, something went wrong in your install!\")\n",
    "\n",
    "#hpyer params here were taken from the matlab implementation but might need to be changed (there were several options and I took the face option)\n",
    "amplify_spatial_Gdown_temporal_ideal(video_location, \"/\", 50,4,50/60,60/60,30, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}