{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys, math, os, logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrtools as pt\n",
    "import platform\n",
    "import glob\n",
    "import ctypes\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ideal_bandpassing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def shiftdim(x, n):\n",
    "    return x.transpose(np.roll(range(x.ndim), -n))\n",
    "\n",
    "\n",
    "def repmat(a,m):\n",
    "    #First, pad out a so it has same dimensionality as m\n",
    "    for i in range(0,m.ndim-a.ndim):\n",
    "        a = np.expand_dims(a,1)\n",
    "    #Now just use numpy tile and return result\n",
    "    return np.tile(a,m.shape)\n",
    "\n",
    "\n",
    "def ideal_bandpassing(input, dim, wl, wh, samplingRate):\n",
    "    # if dim is greater than the dimensionality (2d, 3d etc) of the input, quit\n",
    "    if (dim > len(input.shape)):\n",
    "        print('Exceed maximum dimension')\n",
    "        return\n",
    "\n",
    "    # This has the effect that input_shifted[0] = input[dim]\n",
    "    input_shifted = shiftdim(input, dim - 1)\n",
    "\n",
    "    # Put the dimensions of input_shifted in a 1d array\n",
    "    Dimensions = np.asarray(input_shifted.shape)\n",
    "\n",
    "    # how many things in the first dimension of input_shifted\n",
    "    n = Dimensions[0]\n",
    "\n",
    "    # get the dimensionality (eg. 2d, 3d etc) of input_shifted\n",
    "    dn = input_shifted.ndim\n",
    "\n",
    "    # creates a vector [1,...,n], the same length as the first dimension of input_shifted\n",
    "    Freq = np.arange(1.0, n + 1)\n",
    "\n",
    "    # Equivalent in python: Freq = (Freq-1)/n*samplingRate\n",
    "    Freq = Freq / n * samplingRate\n",
    "\n",
    "    # Create boolean mask same size as Freq, true in between the frequency limits wl,wh\n",
    "    mask = (Freq > wl) & (Freq < wh)\n",
    "\n",
    "    Dimensions[0] = 1\n",
    "    mask = repmat(mask, np.ndarray(Dimensions))\n",
    "\n",
    "    # F = fft(X,[],dim) and F = fft(X,n,dim) applies the FFT operation across the dimension dim.\n",
    "    # Python: F = np.fftn(a=input_shifted,axes=0)\n",
    "    F = np.fft.fftn(a=input_shifted, axes=[0])\n",
    "\n",
    "    # So we are indexing array F using boolean not mask, and setting those values of F to zero, so the others pass thru\n",
    "    # Python: F[ np.logical_not(mask) ]\n",
    "    F[np.logical_not(mask)] = 0\n",
    "\n",
    "    # Get the real part of the inverse fourier transform of the filtered input\n",
    "    filtered = np.fft.ifftn(a=F, axes=[0]).real\n",
    "\n",
    "    filtered = filtered.astype(np.float32)\n",
    "\n",
    "    filtered = shiftdim(filtered, dn - (dim - 1))\n",
    "\n",
    "    return filtered\n",
    "#\n",
    "# def ideal_bandpassing(input, dim, wl, wh, fs):\n",
    "#     if dim > np.asarray(input.shape).ndim:\n",
    "#         print('Exceed maximum dimension')\n",
    "#     input_shifted = shiftdim(input, dim - 1)  # need to implement shift_dim\n",
    "#     dimension = np.asarray(input_shifted.shape)\n",
    "#\n",
    "#     n = dimension[0]\n",
    "#     dn = input_shifted.ndim\n",
    "#\n",
    "#     Freq = np.arange(n)\n",
    "#     Freq = Freq / n * fs  # removed minus 1 because the array start at 0 and matlab starts at 1 so in matalb yousould subtract by 1\n",
    "#     mask = (Freq > wl) & (Freq < wh)\n",
    "#     dimension[0] = 1\n",
    "#     mask = mask.flatten('F')\n",
    "#     # tmp = repmat(mask,dimension)\n",
    "#     mask = np.tile(mask, np.ndarray(dimension))\n",
    "#     F = np.fft.fft(input_shifted, axis=0)\n",
    "#     mask.resize(F.shape)\n",
    "#     F[~mask] = 0  # dont know what is this\n",
    "#\n",
    "#     filtered = np.fft.ifft(a=F, axis=0).real\n",
    "#     filtered = filtered.astype(np.float32)\n",
    "#\n",
    "#     filtered = shiftdim(filtered, dn - (dim - 1))\n",
    "#\n",
    "#     return filtered"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### build_gdown_stack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_gdown_stack(vid_file, start_index, end_index, level):\n",
    "    vid = cv2.VideoCapture(vid_file)\n",
    "    vid_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    vid_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    n_channels = 3\n",
    "\n",
    "    suc, temp = vid.read()\n",
    "    temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    # frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)  # im2double\n",
    "    frame = im2double(temp)\n",
    "    frame = color.rgb2yiq(frame)\n",
    "    # frame = rgb2ntsc(frame)\n",
    "\n",
    "    blurred = blur_dn_clr(frame, level)  # need to implement this\n",
    "\n",
    "    gdown_stack = np.zeros((end_index - start_index + 1, blurred.shape[0], blurred.shape[1], blurred.shape[2]))\n",
    "    gdown_stack[0, :, :, :] = blurred\n",
    "\n",
    "    for k in range(start_index, end_index + 1):\n",
    "        succ, temp = vid.read()\n",
    "        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "        frame = im2double(temp)\n",
    "        # frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)  # im2double\n",
    "        # frame = rgb2ntsc(frame)\n",
    "        frame = color.rgb2yiq(frame)\n",
    "        blurred = blur_dn_clr(frame, level)\n",
    "        gdown_stack[k, :, :, :] = blurred\n",
    "\n",
    "    return gdown_stack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### amplify_spatial_Gdown_temporal_ideal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def im2double(im):\n",
    "    info = np.iinfo(im.dtype)  # Get the data type of the input image\n",
    "    return im.astype(np.float) / info.max  # Divide all values by the largest possible value in the datatype\n",
    "\n",
    "\n",
    "def amplify_spatial_Gdown_temporal_ideal(vid_file, out_file, alpha, level, fl, fh, fs, chrom_attenuation):\n",
    "    out_name = \"out2.avi\"\n",
    "    vid = cv2.VideoCapture(vid_file)\n",
    "    fr = vid.get(cv2.CAP_PROP_FPS)\n",
    "    len_ = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    vid_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    vid_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    start_index = 0\n",
    "    end_index = len_ - 10\n",
    "\n",
    "    cap_size = (vid_width, vid_height)  # this is the size of my source video\n",
    "    vid_out = cv2.VideoWriter()\n",
    "    fourcc = vid_out.fourcc('j', 'p', 'e', 'g')  # note the lower case\n",
    "    success = vid_out.open(out_name, fourcc, fr, cap_size, True)\n",
    "\n",
    "    logging.info('Spatial filtering...')\n",
    "    gdown_stack = build_gdown_stack(vid_file, start_index, end_index, level)\n",
    "    logging.info('Finished')\n",
    "\n",
    "    logging.info('Temporal filtering...')\n",
    "    filtered_stack = ideal_bandpassing(gdown_stack, 1, fl, fh, fs)\n",
    "    logging.info('Finished')\n",
    "\n",
    "    # amplify\n",
    "    filtered_stack[:, :, :, 0] = filtered_stack[:, :, :, 0] * alpha\n",
    "    filtered_stack[:, :, :, 1] = filtered_stack[:, :, :, 1] * alpha * chrom_attenuation\n",
    "    filtered_stack[:, :, :, 2] = filtered_stack[:, :, :, 2] * alpha * chrom_attenuation\n",
    "\n",
    "    logging.info('Rendering...')\n",
    "\n",
    "    for k in range(start_index, end_index + 1):\n",
    "        succ, temp = vid.read()\n",
    "        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "        # frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)  # im2double\n",
    "        frame = im2double(temp)\n",
    "        frame = color.rgb2yiq(frame)\n",
    "        filtered = (filtered_stack[k, :, :, :]).squeeze()\n",
    "        filtered = cv2.resize(filtered, (vid_width, vid_height), 0, 0, cv2.INTER_LINEAR)\n",
    "        filtered = filtered + frame\n",
    "        frame = color.yiq2rgb(filtered)\n",
    "        frame *= 255\n",
    "        frame = np.clip(frame, 0, 255)\n",
    "        frame = cv2.convertScaleAbs(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        vid_out.write(frame)\n",
    "\n",
    "    logging.info('Finished')\n",
    "    vid_out.release()\n",
    "    vid.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## filters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def binomial_filter(sz):\n",
    "    if sz < 2:\n",
    "        logging.warning('size argument must be larger than 1')\n",
    "    kernel = [0.5, 0.5]\n",
    "    for n in range(0, sz - 2):\n",
    "        kernel = np.convolve([0.5, 0.5], kernel)\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def named_filter(name):\n",
    "    if name[:5] == 'binom':\n",
    "        kernel = np.sqrt(2) * binomial_filter(int(name[5:]))\n",
    "    elif name == 'qmf5':\n",
    "        kernel = np.asarray((-0.076103, 0.3535534, 0.8593118, 0.3535534, -0.076103))\n",
    "    elif name == 'qmf9':\n",
    "        kernel = np.asarray((0.02807382, -0.060944743, -0.073386624, 0.41472545, 0.7973934,\n",
    "                             0.41472545, -0.073386624, -0.060944743, 0.02807382))\n",
    "    elif name == 'qmf13':\n",
    "        kernel = np.asarray((-0.014556438, 0.021651438, 0.039045125, -0.09800052,\n",
    "                             -0.057827797, 0.42995453, 0.7737113, 0.42995453, -0.057827797,\n",
    "                             -0.09800052, 0.039045125, 0.021651438, -0.014556438))\n",
    "    elif name == 'qmf8':\n",
    "        kernel = np.sqrt(2) * np.asarray((0.00938715, -0.07065183, 0.06942827, 0.4899808,\n",
    "                                          0.4899808, 0.06942827, -0.07065183, 0.00938715))\n",
    "    elif name == 'qmf12':\n",
    "        kernel = np.sqrt(2) * np.asarray((-0.003809699, 0.01885659, -0.002710326, -0.08469594,\n",
    "                                          0.08846992, 0.4843894, 0.4843894, 0.08846992, -0.08469594, -0.002710326,\n",
    "                                          0.01885659, -0.003809699))\n",
    "    elif name == 'qmf16':\n",
    "        kernel = np.sqrt(2) * np.asarray((0.001050167, -0.005054526, -0.002589756, 0.0276414, -0.009666376,\n",
    "                                          -0.09039223, 0.09779817, 0.4810284, 0.4810284, 0.09779817, -0.09039223,\n",
    "                                          -0.009666376,\n",
    "                                          0.0276414, -0.002589756, -0.005054526, 0.001050167))\n",
    "    elif name == 'haar':\n",
    "        kernel = np.asarray((1, 1)) / np.sqrt(2)\n",
    "    elif name == 'daub2':\n",
    "        kernel = np.asarray((0.482962913145, 0.836516303738, 0.224143868042, -0.129409522551))\n",
    "    elif name == 'daub3':\n",
    "        kernel = np.asarray((0.332670552950, 0.806891509311, 0.459877502118, -0.135011020010,\n",
    "                             -0.085441273882, 0.035226291882))\n",
    "    elif name == 'daub4':\n",
    "        kernel = np.asarray((0.230377813309, 0.714846570553, 0.630880767930, -0.027983769417,\n",
    "                             -0.187034811719, 0.030841381836, 0.032883011667, -0.010597401785))\n",
    "    elif name == 'gauss5':  # for backward-compatibility\n",
    "        kernel = np.sqrt(2) * np.asarray((0.0625, 0.25, 0.375, 0.25, 0.0625))\n",
    "    elif name == 'gauss3':  # for backward-compatibility\n",
    "        kernel = np.sqrt(2) * np.asarray((0.25, 0.5, 0.25))\n",
    "    else:\n",
    "        logging.warning('Bad filter name: ', name)\n",
    "        return\n",
    "\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def parse_filter(filt, normalize=True):\n",
    "    if isinstance(filt, str):\n",
    "        filt = named_filter(filt)\n",
    "\n",
    "    elif isinstance(filt, np.ndarray) or isinstance(filt, list) or isinstance(filt, tuple):\n",
    "        filt = np.array(filt)\n",
    "        if filt.ndim == 1:\n",
    "            filt = np.reshape(filt, (filt.shape[0], 1))\n",
    "        elif filt.ndim == 2 and filt.shape[0] == 1:\n",
    "            filt = np.reshape(filt, (-1, 1))\n",
    "\n",
    "    # TODO expand normalization options\n",
    "    if normalize:\n",
    "        filt = filt / filt.sum()\n",
    "\n",
    "    return filt\n",
    "\n",
    "\n",
    "# def blur_dn(image, n_levels=1, filt='binom5'):\n",
    "#     if image.ndim == 1:\n",
    "#         image = image.reshape(-1, 1)\n",
    "#\n",
    "#     filt = parse_filter(filt)\n",
    "#     filt = filt / np.sum(filt.flatten('F'))  # normalize\n",
    "#     if n_levels > 1:\n",
    "#         image = blur_dn(image, n_levels - 1, filt)\n",
    "#\n",
    "#     if n_levels >= 1:\n",
    "#         if image.shape[1] == 1:\n",
    "#             # 1D image [M, 1] and 1D filter [N, 1]\n",
    "#             res = corr_dn(image=image, filt=filt, step=(2, 1))\n",
    "#\n",
    "#         elif image.shape[0] == 1:\n",
    "#             # 1D image [1, M] and 1D filter [N, 1]\n",
    "#             res = corr_dn(image=image, filt=filt.T, step=(1, 2))\n",
    "#\n",
    "#         elif filt.shape[1] == 1:\n",
    "#             # 2D image and 1D filter [N, 1]\n",
    "#             res = corr_dn(image=image, filt=filt, step=(2, 1))\n",
    "#             res = corr_dn(image=res, filt=filt.T, step=(1, 2))\n",
    "#\n",
    "#         else:\n",
    "#             # 2D image and 2D filter\n",
    "#             res = corr_dn(image=image, filt=filt, step=(2, 2))\n",
    "#\n",
    "#     else:\n",
    "#         res = image\n",
    "#\n",
    "#     return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Blur dn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def blur_dn(im, nlevs=1, filt='binom5'):\n",
    "    if type(filt) == str:\n",
    "        filt = named_filter(filt)\n",
    "    filt = filt / np.sum(filt.flatten('F'))\n",
    "    if nlevs > 1:\n",
    "        im = blur_dn(im, nlevs - 1, filt)\n",
    "\n",
    "    if nlevs >= 1:\n",
    "        if np.asarray(im.shape).ndim == 1:\n",
    "            if np.asarray(filt.shape).ndim != 1:\n",
    "                logging.warning('Cant apply 2D filter to 1D signal')\n",
    "                return\n",
    "            if im.ndim == 1:\n",
    "                filt = filt.flatten('F')\n",
    "            else:\n",
    "                filt = filt.flatten('F')\n",
    "                filt = np.conjugate(filt).T\n",
    "                filt = filt.reshape(-1, 1)\n",
    "            res = corr_dn(im, filt, 'reflect1', tuple(map(lambda x: int(not x == 1) + 1, im.shape)))\n",
    "        elif np.asarray(filt.shape).ndim == 1:\n",
    "            filt = filt.flatten(\"F\")\n",
    "            res = corr_dn(im, filt, 'reflect1', (2, 1))\n",
    "            res = corr_dn(res, filt, 'reflect1', (1, 2))\n",
    "        else:\n",
    "            res = corr_dn(im, filt, 'reflect1', (2, 2))\n",
    "    else:\n",
    "        res = im\n",
    "    return res\n",
    "\n",
    "\n",
    "def blur_dn_clr(im, n_levs=1, filt='binom5'):\n",
    "    # tmp = pt.blurDn(im[:,:,0],nlevs,filt)\n",
    "    # tmp = pt.blurDn(im[:, :, 0].copy(), n_levs, filt)\n",
    "    tmp = blur_dn(im[:, :, 0].copy(), n_levs, filt)\n",
    "    out = np.zeros((tmp.shape[0], tmp.shape[1], im.shape[2]))\n",
    "    out[:, :, 0] = tmp\n",
    "    for clr in range(1, im.shape[2]):\n",
    "        # out[:, :, clr] = pt.blur_dn(im[:, :, clr], n_levs, filt)\n",
    "        out[:, :, clr] = blur_dn(im[:, :, clr], n_levs, filt)\n",
    "    return out\n",
    "\n",
    "\n",
    "# def corr_dn(nhls, phls, nrhs, prhs):\n",
    "#     logging.info(\"Parameters received:\\n\" + str(nhls) + \"\\n\" + str(phls) +\n",
    "#                  \"\\n\" + str(nrhs) + \"\\n\" + str(prhs))\n",
    "#     x_start = 1\n",
    "#     x_step = 1\n",
    "#     y_start = 1\n",
    "#     y_step = 1\n",
    "#\n",
    "#     edges = 'reflect1'\n",
    "#     edges = 'reflect1'\n",
    "#\n",
    "#     logging.info(prhs[0])\n",
    "#     arg0 = prhs[0]\n",
    "#     image = arg0\n",
    "#     x_idim = int(arg0.shape[0])\n",
    "#     y_idim = int(arg0.shape[1])\n",
    "#\n",
    "#     arg1 = prhs[1]\n",
    "#     flit = arg1.data\n",
    "#     x_fdim = int(arg1.shape[0])\n",
    "#     y_fdim = int(arg1.shape[1])\n",
    "#\n",
    "#     x_start -= 1\n",
    "#     y_start -= 1\n",
    "#\n",
    "#     x_rdim = (x_stop-x_start+x_step-1) / x_step\n",
    "#     y_rdim = (y_stop-y_start+y_step-1) / y_step\n",
    "#\n",
    "#     plhs[0] = np.zeros((x_rdim, y_rdim))\n",
    "#     result = plhs[0]\n",
    "#\n",
    "#     if edges == \"circular\":\n",
    "#         pt.internal_wrap_reduce(image, x_idim, y_idim, flit, x_fdim, y_fdim,\n",
    "#                x_start, x_step, y_start, y_step,\n",
    "#                result)\n",
    "#     else:\n",
    "#         pt.internal_reduce(image, x_idim, y_idim, flit, x_fdim, y_fdim,\n",
    "#                x_start, x_step, y_start, y_step,\n",
    "#                result)\n",
    "#     return result\n",
    "\n",
    "# def corr_dn(im,file,edges,step = [1,1],start = [1,1]):\n",
    "#     stop = len(im)\n",
    "#     filt = filt[filt.shape[0]:-1:0,filt.shape[1]:-1:0]\n",
    "#     temp = rconv2(im,filt)\n",
    "#\n",
    "#     res = tmp[start[0]:step[0]:stop[0],start[1]:step[1]:stop[1]]\n",
    "#     return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# corr down"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def corr_dn(image, filt, edge_type='reflect1', step=(1, 1), start=(0, 0),\n",
    "            stop=None):\n",
    "    image = image.copy().astype(float)\n",
    "    filt = filt.copy().astype(float)\n",
    "\n",
    "    if image.shape[0] < filt.shape[0] or image.shape[1] < filt.shape[1]:\n",
    "        raise Exception(\"Signal smaller than filter in corresponding dimension: \", image.shape, filt.shape,\n",
    "                        \" see parse filter\")\n",
    "\n",
    "    if edge_type not in ['circular', 'reflect1', 'reflect2', 'repeat', 'zero', 'extend', 'dont-compute']:\n",
    "        raise Exception(\"Don't know how to do convolution with edge_type %s!\" % edge_type)\n",
    "\n",
    "    if filt.ndim == 1:\n",
    "        filt = filt.reshape(1, -1)\n",
    "\n",
    "    if stop is None:\n",
    "        stop = (image.shape[0], image.shape[1])\n",
    "\n",
    "    rxsz = len(range(start[0], stop[0], step[0]))\n",
    "    rysz = len(range(start[1], stop[1], step[1]))\n",
    "    result = np.zeros((rxsz, rysz))\n",
    "\n",
    "    if edge_type == 'circular':\n",
    "        lib.internal_wrap_reduce(image.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                                 image.shape[1], image.shape[0],\n",
    "                                 filt.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                                 filt.shape[1], filt.shape[0],\n",
    "                                 start[1], step[1], stop[1], start[0], step[0],\n",
    "                                 stop[0],\n",
    "                                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double)))\n",
    "    else:\n",
    "        tmp = np.zeros((filt.shape[0], filt.shape[1]))\n",
    "        lib.internal_reduce(image.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            image.shape[1], image.shape[0],\n",
    "                            filt.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            tmp.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            filt.shape[1], filt.shape[0],\n",
    "                            start[1], step[1], stop[1], start[0], step[0],\n",
    "                            stop[0],\n",
    "                            result.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "                            edge_type.encode('ascii'))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def reconv2(a, b, ctr):\n",
    "    if len(a[1]) >= len(b[1]) and len(a[2]) >= len(b[2]):\n",
    "        large = a\n",
    "        small = b\n",
    "    elif len(a[1]) <= len(b[1]) and len(a[2]) <= len(b[2]):\n",
    "        large = b\n",
    "        small = a\n",
    "    else:\n",
    "        raise Exception(\"one arg must be larger than the other in both dimensions!\")\n",
    "\n",
    "    ly = len(large[1])\n",
    "    lx = len(large[2])\n",
    "    sy = len(small[1])\n",
    "    sx = len(small[2])\n",
    "\n",
    "    \"\"\"\n",
    "    These values are one less than the index of the small mtx that falls on\n",
    "    the border pixel of the large matrix when computing the first\n",
    "    convolution response sample:\n",
    "    \"\"\"\n",
    "    sy2 = math.floor((sy + ctr - 1) / 2)\n",
    "    sx2 = math.floor((sx + ctr - 1) / 2)\n",
    "\n",
    "    # pad with reflected copies\n",
    "    clarge = np.asarray(np.block(large[sy - sy2:-1:2, sx - sx2:-1:2], large[sy - sy2:-1:2, :],\n",
    "                                 large[sy - sy2:-1:2, lx - 1:-1:lx - sx2]),\n",
    "                        np.block(large[:, sx - sx2:-1:2], large, large[:, lx - 1:-1:lx - sx2]),\n",
    "                        np.block(large[ly - 1:-1:ly - sy2, sx - sx2:-1:2], large[ly - 1:-1:ly - sy2, :],\n",
    "                                 large[ly - 1:-1:ly - sy2, lx - 1:-1:lx - sx2]))\n",
    "\n",
    "    c = scipy.signal.convolve2d(clarge, small, boundary='valid', mode='same')\n",
    "\n",
    "    return c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running the algorithm:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "FORMAT = '[%(asctime)s] [%(levelname)s] [%(funcName)s] [%(lineno)d] : %(message)s'\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "logging.info(\"Starting ...\")\n",
    "if platform.system() == \"Windows\":\n",
    "    seperator = \"\\\\\"\n",
    "else:\n",
    "    seperator = \"/\"\n",
    "\n",
    "dir = \"perry-all-2\"\n",
    "# should be a parameter of the engine\n",
    "dataset_location = \"..\" + seperator + \"dataset\" + seperator + \"good_sync\" + seperator\n",
    "specific_dir = dir\n",
    "video_location = dataset_location + specific_dir + seperator + \"test1.mp4\"\n",
    "\n",
    "libpath = glob.glob(\n",
    "    \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pyrtools/pyramids/c/wrapConv.cpython-38-darwin.so\")\n",
    "logging.info(\"libpath:\" + str(libpath))\n",
    "\n",
    "# load the c library\n",
    "if len(libpath) > 0:\n",
    "    lib = ctypes.cdll.LoadLibrary(libpath[0])\n",
    "else:\n",
    "    logging.warning(\"Can't load in C code, something went wrong in your install!\")\n",
    "\n",
    "# hpyer params here were taken from the matlab implementation but might need to be changed (there were several options and I took the face option)\n",
    "amplify_spatial_Gdown_temporal_ideal(video_location, \"/\", 50, 4, 50 / 60, 60 / 60, 30, 1)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}