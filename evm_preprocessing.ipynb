{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyrtools'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-0e229f28af39>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mpyrtools\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlogging\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pyrtools'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pyrtools as pt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def amplify_spatial_Gdown_temporal_ideal(vid_file,out_file,alpha,level,fl,fh,fs,chrom_attenuation):\n",
    "    out_name = \"out.avi\"\n",
    "    vid = cv2.VideoCapture(vid_file)\n",
    "    fr = vid.get(cv2.CAP_PROP_FPS)\n",
    "    len_ = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    vid_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    vid_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    start_index = 0\n",
    "    end_index = len_-10\n",
    "\n",
    "    cap_size = (vid_width, vid_height)  # this is the size of my source video\n",
    "    vid_out = cv2.VideoWriter()\n",
    "    fourcc = vid_out.fourcc('j', 'p', 'e', 'g')  # note the lower case\n",
    "    success = vid_out.open(out_name, fourcc, fr, cap_size, True)\n",
    "\n",
    "    print('Spatial filtering...')\n",
    "    gdown_stack = build_gdown_stack(vid_file,start_index,end_index,level)\n",
    "    print('Finished')\n",
    "\n",
    "    print('Temporal filtering...')\n",
    "    filtered_stack = ideal_bandpassing(gdown_stack,1,fl,fh,fs)\n",
    "    print('Finished')\n",
    "\n",
    "    #amplify\n",
    "    filtered_stack[:,:,:,0] = filtered_stack[:,:,:,0] * alpha\n",
    "    filtered_stack[:,:,:,1] = filtered_stack[:,:,:,1] * alpha * chrom_attenuation\n",
    "    filtered_stack[:,:,:,2] = filtered_stack[:,:,:,2] * alpha * chrom_attenuation\n",
    "\n",
    "    print('Rendering...')\n",
    "\n",
    "    for k in range(start_index,end_index+1):\n",
    "        succ,temp = vid.read()\n",
    "\n",
    "        frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX) # im2double\n",
    "        frame = rgb2ntsc(frame)\n",
    "\n",
    "        filtered = np.squeeze(filtered_stack[k, :, :, :])\n",
    "        filtered = cv2.resize(filtered, (vidWidth, vidHeight), 0, 0, cv2.INTER_LINEAR)\n",
    "\n",
    "        filtered = filtered + frame\n",
    "\n",
    "        frame = ntsc2rgb(filtered)\n",
    "\n",
    "        frame = np.clip(frame, 0, 255)\n",
    "        frame = cv2.convertScaleAbs(frame)\n",
    "\n",
    "        vid_out.write(frame)\n",
    "\n",
    "\n",
    "    print('Finished')\n",
    "    vid_out.release()\n",
    "    vid.release()\n",
    "\n",
    "def rgb2ntsc(frame):\n",
    "    YIQ = np.ndarray(frame.shape)\n",
    "\n",
    "    YIQ[:, :, 0] = 0.299 * frame[:, :, 0] + 0.587 * frame[:, :, 1] + 0.114 * frame[:, :, 2]\n",
    "    YIQ[:, :, 1] = 0.59590059 * frame[:, :, 0] + (-0.27455667) * frame[:, :, 1] + (-0.32134392) * frame[:, :, 2]\n",
    "    YIQ[:, :, 2] = 0.21153661 * frame[:, :, 0] + (-0.52273617) * frame[:, :, 1] + 0.31119955 * frame[:, :, 2]\n",
    "    return YIQ\n",
    "\n",
    "\n",
    "def ntsc2rgb(frame):\n",
    "    RGB = np.ndarray(frame.shape)\n",
    "    RGB[:, :, 0] = 1.00000001 * frame[:, :, 0] + 0.95598634 * frame[:, :, 1] + 0.6208248 * frame[:, :, 2]\n",
    "    RGB[:, :, 1] = 0.99999999 * frame[:, :, 0] + (-0.27201283) * frame[:, :, 1] + (-0.64720424) * frame[:, :, 2]\n",
    "    RGB[:, :, 2] = 1.00000002 * frame[:, :, 0] + (-1.10674021) * frame[:, :, 1] + 1.70423049 * frame[:, :, 2]\n",
    "    return RGB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def binomial_filter(sz):\n",
    "    if sz < 2:\n",
    "        print('size argument must be larger than 1')\n",
    "    kernel = [0.5,0.5]\n",
    "    for n in range(0,sz-2):\n",
    "        kernel = np.convolve([0.5,0.5],kernel)\n",
    "    return kernel\n",
    "\n",
    "def named_filter(name):\n",
    "    if name[:5] == 'binom':\n",
    "        kernel = np.sqrt(2) * binomial_filter(int(name[5:]))\n",
    "    elif name == 'qmf5':\n",
    "        kernel = np.asarray((-0.076103, 0.3535534, 0.8593118, 0.3535534, -0.076103))\n",
    "    elif name == 'qmf9':\n",
    "        kernel = np.asarray((0.02807382, -0.060944743, -0.073386624, 0.41472545, 0.7973934,\n",
    "                             0.41472545, -0.073386624, -0.060944743, 0.02807382))\n",
    "    elif name == 'qmf13':\n",
    "        kernel = np.asarray((-0.014556438, 0.021651438, 0.039045125, -0.09800052,\n",
    "                             -0.057827797, 0.42995453, 0.7737113, 0.42995453, -0.057827797,\n",
    "                             -0.09800052, 0.039045125, 0.021651438, -0.014556438))\n",
    "    elif name == 'qmf8':\n",
    "        kernel = np.sqrt(2) * np.asarray((0.00938715, -0.07065183, 0.06942827, 0.4899808,\n",
    "                                          0.4899808, 0.06942827, -0.07065183, 0.00938715))\n",
    "    elif name == 'qmf12':\n",
    "        kernel = np.sqrt(2) * np.asarray((-0.003809699, 0.01885659, -0.002710326, -0.08469594,\n",
    "                                          0.08846992, 0.4843894, 0.4843894, 0.08846992, -0.08469594, -0.002710326,\n",
    "                                          0.01885659, -0.003809699))\n",
    "    elif name == 'qmf16':\n",
    "        kernel = np.sqrt(2) * np.asarray((0.001050167, -0.005054526, -0.002589756, 0.0276414, -0.009666376,\n",
    "                                          -0.09039223, 0.09779817, 0.4810284, 0.4810284, 0.09779817, -0.09039223,\n",
    "                                          -0.009666376,\n",
    "                                          0.0276414, -0.002589756, -0.005054526, 0.001050167))\n",
    "    elif name == 'haar':\n",
    "        kernel = np.asarray((1, 1)) / np.sqrt(2)\n",
    "    elif name == 'daub2':\n",
    "        kernel = np.asarray((0.482962913145, 0.836516303738, 0.224143868042, -0.129409522551))\n",
    "    elif name == 'daub3':\n",
    "        kernel = np.asarray((0.332670552950, 0.806891509311, 0.459877502118, -0.135011020010,\n",
    "                             -0.085441273882, 0.035226291882))\n",
    "    elif name == 'daub4':\n",
    "        kernel = np.asarray((0.230377813309, 0.714846570553, 0.630880767930, -0.027983769417,\n",
    "                             -0.187034811719, 0.030841381836, 0.032883011667, -0.010597401785))\n",
    "    elif name == 'gauss5':  # for backward-compatibility\n",
    "        kernel = np.sqrt(2) * np.asarray((0.0625, 0.25, 0.375, 0.25, 0.0625))\n",
    "    elif name == 'gauss3':  # for backward-compatibility\n",
    "        kernel = np.sqrt(2) * np.asarray((0.25, 0.5, 0.25))\n",
    "    else:\n",
    "        print('Bad filter name: ', name)\n",
    "        return\n",
    "\n",
    "    return kernel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def blur_dn(im,nlevs = 1,filt = 'binom5'):\n",
    "    if type(filt) == str:\n",
    "        filt = named_filter(filt)\n",
    "    filt = filt/ np.sum(filt.flatten('F'))\n",
    "\n",
    "    if nlevs > 1:\n",
    "        im = blur_dn(im,nlevs-1,filt)\n",
    "\n",
    "    if nlevs>=1:\n",
    "        if np.any(np.shape(im) ==1):\n",
    "            if ~np.any(np.shape(filt) == 1):\n",
    "                print('Cant apply 2D filter to 1D signal')\n",
    "                return\n",
    "            if im.shape[1] == 1:\n",
    "                filt = filt.flatten('F')\n",
    "            else:\n",
    "                filt =filt.flatten('F').H\n",
    "            arr = np.asarray(im.shape)\n",
    "            for i in arr:\n",
    "                arr[i] = int(np.logical_not(arr[i],1))\n",
    "            arr = arr +1\n",
    "            res = corr_dn(im,filt,'reflect1',arr)\n",
    "        elif np.any(np.shape(filt) == 1):\n",
    "            filt = filt.flatten(\"F\")\n",
    "            res = corr_dn(im,filt,'reflect1',np.asarray([2,1]))\n",
    "            res = corr_dn(res,filt,'reflect1',np.asarray([1,2]))\n",
    "        else:\n",
    "            res = corr_dn(im,filt,'reflect1',np.asarray([2,2]))\n",
    "    else:\n",
    "        res = im\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def blur_dn_clr(im,nlevels=1,filt='binom5'):\n",
    "\n",
    "    tmp = blur_dn(im[:,:,0],nlevels,filt)\n",
    "    out = np.zeros(tmp.shape[0],temp.shape[1],im.shape[2])\n",
    "    out[:,:,0] = tmp\n",
    "    for clr in range(1, im.shape[2]):\n",
    "        out[:, :, clr] = blur_dn(im[:, :, clr], nlevs, filt)\n",
    "\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_gdown_stack(vid_file,start_index,end_index,level):\n",
    "\n",
    "    vid = cv2.VideoCapture(vid_file)\n",
    "    vid_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    vid_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    n_channels = 3\n",
    "\n",
    "    suc,temp = vid.read()\n",
    "    frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX) # im2double\n",
    "    frame = rgb2ntsc(frame)\n",
    "\n",
    "    blurred = blur_dn_clr(frame,level) # need to implement this\n",
    "\n",
    "    gdown_stack = np.zeros(end_index - start_index +1, blurred.shape[0],blurred.shape[1],blurred.shape[2])\n",
    "    gdown_stack[0,:,:,:] = blurred\n",
    "\n",
    "    for k in range(start_index,end_index+1):\n",
    "\n",
    "\n",
    "        succ,temp = vid.read()\n",
    "\n",
    "        frame = cv2.normalize(temp.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX) # im2double\n",
    "        frame = rgb2ntsc(frame)\n",
    "        blurred = blue_dn_clr(frame,level)\n",
    "        gdown_stack[k,:,:,:] = blurred\n",
    "\n",
    "    return gdown_stack\n",
    "\n",
    "def rgb2ntsc(frame):\n",
    "    YIQ = np.ndarray(frame.shape)\n",
    "\n",
    "    YIQ[:, :, 0] = 0.299 * frame[:, :, 0] + 0.587 * frame[:, :, 1] + 0.114 * frame[:, :, 2]\n",
    "    YIQ[:, :, 1] = 0.59590059 * frame[:, :, 0] + (-0.27455667) * frame[:, :, 1] + (-0.32134392) * frame[:, :, 2]\n",
    "    YIQ[:, :, 2] = 0.21153661 * frame[:, :, 0] + (-0.52273617) * frame[:, :, 1] + 0.31119955 * frame[:, :, 2]\n",
    "    return YIQ\n",
    "\n",
    "\n",
    "def ntsc2rgb(frame):\n",
    "    RGB = np.ndarray(frame.shape)\n",
    "    RGB[:, :, 0] = 1.00000001 * frame[:, :, 0] + 0.95598634 * frame[:, :, 1] + 0.6208248 * frame[:, :, 2]\n",
    "    RGB[:, :, 1] = 0.99999999 * frame[:, :, 0] + (-0.27201283) * frame[:, :, 1] + (-0.64720424) * frame[:, :, 2]\n",
    "    RGB[:, :, 2] = 1.00000002 * frame[:, :, 0] + (-1.10674021) * frame[:, :, 1] + 1.70423049 * frame[:, :, 2]\n",
    "    return RGB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def corr_dn(nhls, phls, nrhs, prhs):\n",
    "    x_start = 1\n",
    "    x_step = 1\n",
    "    y_start = 1\n",
    "    y_step = 1\n",
    "\n",
    "    edges = 'reflect1'\n",
    "\n",
    "    arg0 = prhs[0]\n",
    "    image = arg0.data\n",
    "    x_idim = int(arg0.shape[0])\n",
    "    y_idim = int(arg0.shape[1])\n",
    "\n",
    "    arg1 = prhs[1]\n",
    "    flit = arg1.data\n",
    "    x_fdim = int(arg1.shape[0])\n",
    "    y_fdim = int(arg1.shape[1])\n",
    "\n",
    "    x_start -= 1\n",
    "    y_start -= 1\n",
    "\n",
    "    x_rdim = (x_stop-x_start+x_step-1) / x_step\n",
    "    y_rdim = (y_stop-y_start+y_step-1) / y_step\n",
    "\n",
    "    plhs[0] = np.zeros((x_rdim, y_rdim))\n",
    "    result = plhs[0]\n",
    "\n",
    "    if edges == \"circular\":\n",
    "        pt.internal_wrap_reduce(image, x_idim, y_idim, flit, x_fdim, y_fdim,\n",
    "               x_start, x_step, y_start, y_step,\n",
    "               result)\n",
    "    else:\n",
    "        pt.internal_reduce(image, x_idim, y_idim, flit, x_fdim, y_fdim,\n",
    "               x_start, x_step, y_start, y_step,\n",
    "               result)\n",
    "    return result\n",
    "# def corr_dn(im,file,edges,step,start,stop):\n",
    "#\n",
    "# \tfilt = filt[filt.shape[0]:-1:0,filt.shape[1]:-1:0]\n",
    "# \ttemp = rconv2(im,filt)\n",
    "#\n",
    "# \tres = tmp[start[0]:step[0]:stop[0],start[1]:step[1]:stop[1]]\n",
    "# \treturn res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reconv2(a,b,ctr):\n",
    "\tif len(a[1]) >= len(b[1]) and len(a[2]) >= len(b[2]):\n",
    "\t\tlarge = a\n",
    "\t\tsmall = b\n",
    "\telif len(a[1]) <= len(b[1]) and len(a[2]) <= len(b[2]):\n",
    "\t\tlarge = b\n",
    "\t\tsmall = a\n",
    "\telse:\n",
    "\t\traise Exception(\"one arg must be larger than the other in both dimensions!\")\n",
    "\n",
    "\tly = len(large[1])\n",
    "\tlx = len(large[2])\n",
    "\tsy = len(small[1])\n",
    "\tsx = len(small[2])\n",
    "\n",
    "\t\"\"\"\n",
    "\tThese values are one less than the index of the small mtx that falls on\n",
    "\tthe border pixel of the large matrix when computing the first\n",
    "\tconvolution response sample:\n",
    "\t\"\"\"\n",
    "\tsy2 = math.floor((sy+ctr-1)/2)\n",
    "\tsx2 = math.floor((sx+ctr-1)/2)\n",
    "\n",
    "\t# pad with reflected copies\n",
    "\tclarge = np.asarray(np.block(large[sy-sy2:-1:2,sx-sx2:-1:2], large[sy-sy2:-1:2,:], large[sy-sy2:-1:2,lx-1:-1:lx-sx2]),\n",
    "\tnp.block(large[:,sx-sx2:-1:2], large, large[:,lx-1:-1:lx-sx2]),\n",
    "\tnp.block(large[ly-1:-1:ly-sy2,sx-sx2:-1:2], large[ly-1:-1:ly-sy2,:], large[ly-1:-1:ly-sy2,lx-1:-1:lx-sx2]))\n",
    "\n",
    "\tc = signal.convolve2d(clarge, small, boundary='valid', mode='same')\n",
    "\n",
    "\treturn c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-ee3ae22812e4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mFORMAT\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'[%(asctime)s] [%(levelname)s] [%(funcName)s] [%(lineno)d] : %(message)s'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbasicConfig\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mFORMAT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mINFO\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Starting ...\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "FORMAT = '[%(asctime)s] [%(levelname)s] [%(funcName)s] [%(lineno)d] : %(message)s'\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "logging.info(\"Starting ...\")\n",
    "if platform.system() == \"Windows\":\n",
    "    seperator = \"\\\\\"\n",
    "else:\n",
    "    seperator = \"/\"\n",
    "\n",
    "dir = \"perry-all-2\"\n",
    "# should be a parameter of the engine\n",
    "dataset_location = \"..\" + seperator + \"dataset\" + seperator + \"good_sync\" + seperator\n",
    "specific_dir = dir\n",
    "video_location = dataset_location + specific_dir + seperator + \"test.mp4\"\n",
    "\n",
    "#hpyer params here were taken from the matlab implementation but might need to be changed (there were several options and I took the face option)\n",
    "amplify_spatial_Gdown_temporal_ideal(video_location, \"/\", 50,4,50/60,60/60,30, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}