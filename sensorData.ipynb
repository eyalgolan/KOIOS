{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(in_filename, file_type):\n",
    "    \"\"\"\n",
    "\n",
    "    :param in_filename:\n",
    "    :param file_type:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for fname in os.listdir(raw_data_dir):\n",
    "        if in_filename in fname and file_type in fname:\n",
    "            return str(fname)\n",
    "        \n",
    "def get_rawdata_json():\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    name = raw_data_dir\n",
    "\n",
    "    metis = {\"events\": get_filename(\"events\", \"csv\"),\n",
    "             \"sensors\": get_filename(\"sensors\", \"csv\")}\n",
    "    sensors ={\"OH1\":\n",
    "                  {\"ACC\":{\"dir\":\"\",\n",
    "                          \"files\":[get_filename(\"ACC\", \"txt\")]},\n",
    "                   \"PPG\":{\"dir\":\"\",\n",
    "                          \"files\":[get_filename(\"PPG\", \"txt\")]}},\n",
    "              \"H10\":\n",
    "                  {\"ECG\":{\"dir\":\"\",\n",
    "                          \"files\":[get_filename(\"ECG\", \"txt\")]},\n",
    "                   \"ACC\":{\"dir\":\"\",\n",
    "                          \"files\":[get_filename(\"ACC\", \"txt\")]}}}\n",
    "    videos = {\"phone\":\n",
    "                  {\"dir\":\"phone\",\n",
    "                   \"files\":[get_filename(\"P\", \"mp4\")]},\n",
    "              \"face\":\n",
    "                  {\"dir\":\"phone\",\n",
    "                   \"files\":\"\"},\n",
    "              \"body\":\n",
    "                  {\"dir\":\"phone\",\n",
    "                   \"files\":\"\"},\n",
    "              \"face_gopro\":\n",
    "                  {\"dir\":\"phone\",\n",
    "                   \"files\":\"\"}}\n",
    "\n",
    "    data = {\"name\":name,\n",
    "            \"metis\":metis,\n",
    "            \"sensors\":sensors,\n",
    "            \"videos\":videos}\n",
    "\n",
    "    raw_json = json.dumps(data, indent=4)\n",
    "    with open(\"data_file.json\", \"w\") as write_file:\n",
    "        json.dump(data, write_file, indent=4)\n",
    "    return raw_json\n",
    "\n",
    "raw_data_dir = \"..\\\\dataset\\\\good_sync\\\\perry-all-2\"\n",
    "raw_json = get_rawdata_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_polar_sensor(sensor_file, sensor_cols=None):\n",
    "    \"\"\"\n",
    "\n",
    "    :param sensor_file:\n",
    "    :param sensor_cols:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if sensor_cols is None:\n",
    "        df = pd.read_csv(sensor_file, delimiter=\" \")\n",
    "    else:\n",
    "        df = pd.read_csv(sensor_file, delimiter=\" \", names=sensor_cols,\n",
    "                         skiprows=1)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ns').dt.round(\n",
    "        '1ms')\n",
    "    df['timestamp'] = df['timestamp'] + pd.DateOffset(years=30, days=-1)\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    return df\n",
    "\n",
    "def create_dataframe_of_sensors():\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    logging.info(\"Obtaining collected data ...\")\n",
    "    data_dict = json.loads(raw_json)\n",
    "    n_sensors = len(data_dict[\"sensors\"])\n",
    "\n",
    "    logging.info(f'Total number of sensors: {n_sensors}')\n",
    "    files, df = {}, {}\n",
    "    for sname, sdata in data_dict['sensors'].items():\n",
    "        for dname, ddata in sdata.items():\n",
    "            sensor = (sname, dname)\n",
    "            files[sensor] = os.path.join(raw_data_dir, ddata['dir'], ddata['files'][0])\n",
    "            logging.info(f'Sensor: {sname} Data: {dname} File: {files[sensor]}')\n",
    "            df[sensor] = get_polar_sensor(files[sensor])\n",
    "            #display(df[sensor].head(5))\n",
    "    return df\n",
    "    \n",
    "sensor_dataframe = create_dataframe_of_sensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sensors_dataframe():\n",
    "    sensor_cols = [\"Time\", \"Junk1\", \"Sensor\", \"X\", \"Y\", \"Z\", \"UX\", \"UY\", \"UZ\",\n",
    "                   \"Junk2\"]\n",
    "    data_dict = json.loads(raw_json)\n",
    "    sensor_files = data_dict['metis']['sensors']\n",
    "\n",
    "    if isinstance(sensor_files, list):\n",
    "        frames = []\n",
    "        for i, f in enumerate(sensor_files):\n",
    "            frames.append(\n",
    "                pd.read_csv(os.path.join(raw_data_dir, f), skiprows=1,\n",
    "                            names=sensor_cols, engine=\"python\",\n",
    "                            usecols=[i for i in range(10)]))\n",
    "            sdf = pd.concat(frames, ignore_index=True)\n",
    "    else:\n",
    "        sdf = pd.read_csv(os.path.join(raw_data_dir, sensor_files), skiprows=1,\n",
    "                          names=sensor_cols, engine=\"python\",\n",
    "                          usecols=[i for i in range(10)])\n",
    "\n",
    "    sdf['DT'] = pd.to_datetime(sdf.Time, errors='coerce',\n",
    "                               format='%Y-%m-%d_%H:%M:%S:%f')\n",
    "    # sdf['DT'] = pd.to_datetime(sdf.Time, errors='coerce', format='%Y-%m-%d %H:%M:%S:%f')\n",
    "    sdf = sdf.drop(labels=[\"Junk1\", \"Junk2\", \"Time\"], axis=1)\n",
    "    sdf['Sensor'] = sdf['Sensor'].astype('category')\n",
    "\n",
    "    sdf.to_csv(\"sdf.csv\")\n",
    "    return sdf\n",
    "\n",
    "sdf = create_sensors_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ef2c1ee1c7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msensor_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mpdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{key[0]}-{key[1]}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mfind_common_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-ef2c1ee1c7b4>\u001b[0m in \u001b[0;36mfind_common_period\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Find commom period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     b = np.max((sensor_dataframe['OH1', 'ACC'].index[0], sensor_dataframe['H10', 'ACC'].index[0],\n\u001b[0m\u001b[1;32m     16\u001b[0m                 pdf.index[0]))\n\u001b[1;32m     17\u001b[0m     e = np.min((sensor_dataframe['OH1', 'ACC'].index[-1], sensor_dataframe['H10', 'ACC'].index[-1],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def plot_acc(df, key, fields, ax, title=''):\n",
    "    if key is None:\n",
    "        cdf = df\n",
    "    else:\n",
    "        if key in df:\n",
    "            cdf = df[key]\n",
    "        else:\n",
    "            logging.info(f'Key ({key}) does not exist')\n",
    "            return\n",
    "    for field in fields:\n",
    "        ax.plot(cdf.index, cdf[field], label=field)\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "\n",
    "def clean_sensor(sensor_df, idx):\n",
    "    logging.info(f'Original number of samples: {sensor_df.shape[0]}')\n",
    "    # Leave unique values per sample\n",
    "    sensor_df = sensor_df.groupby('DT').mean()\n",
    "    logging.info(\n",
    "        f'After duplicate removal, number of samples: {sensor_df.shape[0]}')\n",
    "    # Add missing data\n",
    "    cidx = idx.union(sensor_df.index)\n",
    "    sensor_df = sensor_df.reindex(cidx).interpolate(method='linear')\n",
    "    sensor_df = sensor_df.loc[idx]\n",
    "    logging.info(\n",
    "        f'After interpolation to 100 samples/sec, number of samples: {sensor_df.shape[0]}')\n",
    "    return sensor_df\n",
    "    \n",
    "def handle_sdf_cleanup(sdf):\n",
    "    idx = pd.date_range(start=sdf.iloc[0]['DT'], end=sdf.iloc[-1]['DT'],\n",
    "                        freq='.01S')\n",
    "\n",
    "    logging.info('Cleaning accelerometer')\n",
    "    acc = clean_sensor(sdf.loc[\n",
    "                           sdf[\"Sensor\"] == \"ICM42605M Accelerometer\", [\n",
    "                               'DT',\n",
    "                               'X',\n",
    "                               'Y',\n",
    "                               'Z']],\n",
    "                       idx)\n",
    "    logging.info('Cleaning magnetometer')\n",
    "    mag = clean_sensor(sdf.loc[\n",
    "                           sdf[\"Sensor\"] == \"AK09918 Magnetometer\", ['DT',\n",
    "                                                                     'X',\n",
    "                                                                     'Y',\n",
    "                                                                     'Z']],\n",
    "                       idx)\n",
    "    mag = mag.reindex(index=acc.index, method='nearest')\n",
    "    logging.info('Cleaning gyroscope')\n",
    "    gyr = clean_sensor(\n",
    "        sdf.loc[\n",
    "            sdf[\"Sensor\"] == \"ICM42605M Gyroscope\", ['DT', 'X', 'Y', 'Z']],\n",
    "        idx)\n",
    "    gyr = gyr.reindex(index=acc.index, method='nearest')\n",
    "\n",
    "    sdf = sdf.set_index('DT')\n",
    "\n",
    "    sensors = ['acc', 'gyr', 'mag']\n",
    "    axes = ['x', 'y', 'z']\n",
    "    pdf = pd.concat([acc, gyr, mag], axis=1)\n",
    "    pdf.columns = pd.MultiIndex.from_product([sensors, axes],\n",
    "                                             names=['Sensor', 'Axis'])\n",
    "    pdf.to_csv(\"pdf.csv\")\n",
    "    sensors = ['acc', 'gyr', 'mag']\n",
    "    axes = ['x', 'y', 'z']\n",
    "    pdf = pd.concat([acc, gyr, mag], axis=1)\n",
    "    pdf.columns = pd.MultiIndex.from_product([sensors, axes],\n",
    "                                             names=['Sensor', 'Axis'])\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), nrows=3, ncols=1, sharex=True)\n",
    "    plot_acc(pdf, None, [('acc', 'x'), ('acc', 'y'), ('acc', 'z')],\n",
    "             ax=ax[0], title='Phone accelerometer')\n",
    "    return pdf\n",
    "pdf = handle_sdf_cleanup(sdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ef2c1ee1c7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msensor_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mpdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{key[0]}-{key[1]}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mfind_common_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-ef2c1ee1c7b4>\u001b[0m in \u001b[0;36mfind_common_period\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Find commom period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     b = np.max((sensor_dataframe['OH1', 'ACC'].index[0], sensor_dataframe['H10', 'ACC'].index[0],\n\u001b[0m\u001b[1;32m     16\u001b[0m                 pdf.index[0]))\n\u001b[1;32m     17\u001b[0m     e = np.min((sensor_dataframe['OH1', 'ACC'].index[-1], sensor_dataframe['H10', 'ACC'].index[-1],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def plot_sensors(self, df):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), nrows=4, ncols=1,\n",
    "                           sharex=True)\n",
    "    self.plot_acc(df, ('OH1', 'ACC'), ['x', 'y', 'z'], ax[0],\n",
    "             'OH1 accelerometer')\n",
    "    self.plot_acc(df, ('H10', 'ACC'), ['x', 'y', 'z'], ax[1],\n",
    "             'H10 accelerometer')\n",
    "    self.plot_acc(df, ('OH1', 'PPG'), ['ch1', 'ch2', 'ch3'], ax[2],\n",
    "             'OH1 PPG')\n",
    "    self.plot_acc(df, ('H10', 'ECG'), ['ecg'], ax[3], 'H10 ECG')\n",
    "    \n",
    "def find_common_period():\n",
    "\n",
    "    # Find commom period\n",
    "    b = np.max((sensor_dataframe['OH1', 'ACC'].index[0], sensor_dataframe['H10', 'ACC'].index[0],\n",
    "                pdf.index[0]))\n",
    "    e = np.min((sensor_dataframe['OH1', 'ACC'].index[-1], sensor_dataframe['H10', 'ACC'].index[-1],\n",
    "                pdf.index[-1]))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), nrows=2, ncols=1)\n",
    "\n",
    "    x, cdf = {}, {}\n",
    "    cdf['phone'] = pdf[(pdf.index > b) & (pdf.index < e)]\n",
    "    x['phone'] = np.sqrt(\n",
    "        cdf['phone'][('acc', 'x')] ** 2 + cdf['phone'][('acc', 'y')] ** 2 +\n",
    "        cdf['phone'][('acc', 'z')] ** 2)\n",
    "\n",
    "    for key in ['OH1', 'H10']:\n",
    "        cdf['phone'] = cdf['phone'].drop_duplicates()\n",
    "        cdf['phone'] = cdf['phone'].reset_index(drop=True)\n",
    "        cdf['phone'] = cdf['phone'].reset_index()\n",
    "        sensor_dataframe[key, 'ACC'] = sensor_dataframe[key, 'ACC'].drop_duplicates()\n",
    "        sensor_dataframe[key, 'ACC'] = sensor_dataframe[key, 'ACC'].reset_index(drop=True)\n",
    "        sensor_dataframe[key, 'ACC'] = sensor_dataframe[key, 'ACC'].reset_index()\n",
    "        cdf[key] = sensor_dataframe[key, 'ACC'].reindex(index=cdf['phone'].index,\n",
    "                                          method='nearest')\n",
    "        x[key] = np.sqrt(\n",
    "            cdf[key]['[ns];X'] ** 2 + cdf[key]['[mg];Y'] ** 2 + cdf[key]['[mg];Z'] ** 2)\n",
    "    logging.info(\n",
    "        f'Phone cut {cdf[\"phone\"].shape[0]} OH1 cut {cdf[\"OH1\"].shape[0]} H10 cut {cdf[\"H10\"].shape[0]}')\n",
    "\n",
    "    bh, ah = sig.butter(4, 1 / (100 / 2), 'highpass')\n",
    "    bl, al = sig.butter(4, 10 / (100 / 2), 'lowpass')\n",
    "\n",
    "    for i in ['phone', 'OH1', 'H10']:\n",
    "        # x[i] -= np.mean(x[i])\n",
    "        x[i] = sig.filtfilt(bh, ah, x[i])\n",
    "        x[i] = np.absolute(x[i])\n",
    "        x[i] = sig.filtfilt(bl, al, x[i])\n",
    "        ax[0].plot(x[i], label=i)\n",
    "    ax[0].legend()\n",
    "\n",
    "    offset = {}\n",
    "    for pair in (('phone', 'OH1'), ('phone', 'H10'), ('H10', 'OH1')):\n",
    "        l = ax[1].xcorr(x[pair[0]], x[pair[1]], maxlags=1000,\n",
    "                        usevlines=False, label=f'{pair[0]} vs. {pair[1]}',\n",
    "                        marker='.', linestyle='-')\n",
    "        offset[pair] = l[0][l[1].argmax()]\n",
    "        logging.info(f'Offset {pair[0]} vs. {pair[1]} is: {offset[pair]}')\n",
    "    ax[1].legend()\n",
    "    plot_sensors(pdf)\n",
    "\n",
    "    for key in sensor_dataframe.keys():\n",
    "        off = offset['phone', key[0]]\n",
    "        logging.info(f'Sensor {key[0]} Data {key[1]} Offset: {off}')\n",
    "        #print(self.sensor_dataframe[key].index)\n",
    "        time_delta = timedelta(milliseconds=0.0 + off * 10)\n",
    "        print(sensor_dataframe[key][\"timestamp;sensor\"])\n",
    "        sensor_dataframe[key]['timestamp;sensor'] = pd.to_datetime(sensor_dataframe[key]['timestamp;sensor'],\n",
    "                                         unit='ns').dt.round('1ms')\n",
    "\n",
    "        sensor_dataframe[key]['adj_timestamp'] = sensor_dataframe[key]['timestamp;sensor'] + time_delta\n",
    "        sensor_dataframe[key] = sensor_dataframe[key].set_index('adj_timestamp')\n",
    "\n",
    "    for key in sensor_dataframe.keys():\n",
    "        idx = pdf.index[(pdf.index >= sensor_dataframe[key].index[0]) & (\n",
    "        (pdf.index <= sensor_dataframe[key].index[-1]))]\n",
    "        aidx = idx.union(sensor_dataframe[key].index)\n",
    "        interp_df = sensor_dataframe[key].reindex(aidx).interpolate(method='linear')\n",
    "        index_df = interp_df.loc[idx]\n",
    "        for column in sensor_dataframe[key].columns:\n",
    "            pdf[f'{key[0]}-{key[1]}', column] = index_df[column]\n",
    "find_common_period()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
