{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "#your_video = \"../dataset/good_sync/perry-all-2/P104_2020-12-06_121257717.mp4\"\n",
    "video_sources = [\"first_video.mp4\", \"second_video.mp4\",\"third_video.mp4\",\n",
    "                 \"fourth_video.mp4\", \"sixth_video.mp4\",\n",
    "                 \"seventh_video.mp4\", \"eight_video.mp4\", \"ninth_video.mp4\"]\n",
    "rotated_video_sources = [\"rotated_\" + source for source in video_sources]\n",
    "for video_source, rotated_source in zip(video_sources, rotated_video_sources):\n",
    "    clip = VideoFileClip(video_source)\n",
    "    clip = clip.rotate(90)\n",
    "    clip.write_videofile(rotated_source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic engine implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-22 10:49:42,086] [INFO] [<module>] [13] : Starting ...\n"
     ]
    }
   ],
   "source": [
    "import face_recognition, PIL.Image, PIL.ImageDraw,math\n",
    "import numpy as np\n",
    "import logging\n",
    "import cv2\n",
    "import platform\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.signal as sig\n",
    "\n",
    "FORMAT = '[%(asctime)s] [%(levelname)s] [%(funcName)s] [%(lineno)d] : %(message)s'\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "logging.info(\"Starting ...\")\n",
    "if platform.system() == \"Windows\":\n",
    "    seperator = \"\\\\\"\n",
    "else:\n",
    "    seperator = \"/\"\n",
    "\n",
    "dir = \"perry-all-2\"\n",
    "# should be a parameter of the engine\n",
    "dataset_location = \"..\" + seperator + \"dataset\" + seperator + \"good_sync\" + seperator\n",
    "specific_dir = dir\n",
    "#video_location = dataset_location + specific_dir + seperator + \"lab1.mp4\"\n",
    "#video_location = \"rotated.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running evm pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#%run ./evm_preprocessing.ipynb\n",
    "# video_location = dataset_location + specific_dir + seperator + \"out.avi\"\n",
    "#video_location=\"out2.avi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting the face landmarks and parsing the ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_roi(frame):\n",
    "    # image = face_recognition.load_image_file(frame) # read image.\n",
    "    face_locations = face_recognition.face_locations(frame,model = 'hog') # detects all the faces in image\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "    \n",
    "    # iterate through all the faces.\n",
    "    for face_location in face_locations:\n",
    "        img = PIL.Image.fromarray(frame)\n",
    "        top,right,bottom,left = face_location # extract all face square points.\n",
    "        diff = math.floor((top - bottom) * 0.15) # 20 percent of the face len (toadd eyebrow top point).\n",
    "        \n",
    "        # finding the forehead\n",
    "        try:\n",
    "            right_eyebrow_landmarks = np.asarray(face_landmarks_list[0]['right_eyebrow']) # right eyebrow points.\n",
    "        except:\n",
    "            return None\n",
    "        right_eyebrow_landmarks.sort(axis=0)\n",
    "        rightest_point = right_eyebrow_landmarks[-1] # The most right point of the ROI(according to x).\n",
    "        top_right_eyebrow = right_eyebrow_landmarks.min(axis = 0)[1]\n",
    "        try:\n",
    "            left_eyebrow_landmarks = np.asarray(face_landmarks_list[0]['left_eyebrow'])\n",
    "        except:\n",
    "            return None\n",
    "        left_eyebrow_landmarks.sort(axis=0)\n",
    "        leftest_point = left_eyebrow_landmarks[0] # the most left point of ROI.(according to x)\n",
    "        top_left_eyebrow = left_eyebrow_landmarks.min(axis = 0)[1]\n",
    "        bottom = min(top_right_eyebrow,top_left_eyebrow).item(0) # bottom point of the forehead.\n",
    "        bottom = bottom - (0.05 * bottom) # improve bottom location by 2 percent.\n",
    "        forehead = img.crop((leftest_point[0], leftest_point[1]+diff, rightest_point[0],bottom+10)) # adding diff to top to make the forehead bigger.\n",
    "\n",
    "        # finding the second ROI:\n",
    "        try:\n",
    "            upper_mouth = np.asarray(face_landmarks_list[0]['top_lip']) # top_lip landmarks\n",
    "        except:\n",
    "            return None\n",
    "        upper_mouth_min = upper_mouth.min(axis = 0)[1] # The  top - lip upper point.\n",
    "        try:\n",
    "            upper_nose = np.asarray(face_landmarks_list[0]['nose_bridge'])\n",
    "        except:\n",
    "            return None\n",
    "        upper_nose_min = upper_nose.min(axis = 0)[1]  # noise bridge upper point.\n",
    "        upper_nose_min += upper_mouth_min * 0.1 # improving the noise bridge upper point.\n",
    "        nose_to_upper_lip = img.crop((leftest_point[0], upper_nose_min, rightest_point[0], upper_mouth_min))\n",
    "\n",
    "        return forehead, nose_to_upper_lip\n",
    "    return None # in case of which no face was detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for bad frames\n",
    "##### R > 95 and G > 40 and B > 20 and R > G and R > B\n",
    "##### Based on https://arxiv.org/ftp/arxiv/papers/1708/1708.02694.pdf page 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "pycharm": {
     "name": "#%%s\n"
    }
   },
   "outputs": [],
   "source": [
    "red_min_val = 95\n",
    "green_min_val = 40\n",
    "blue_min_val = 20\n",
    "red_green_max_diff = 15\n",
    "def good_frame(blue, green, red):\n",
    "    if red <= red_min_val:\n",
    "        logging.warning(\"bad frame detected, reason: red > red_min_val\")\n",
    "        return False\n",
    "    if green <= green_min_val:\n",
    "        logging.warning(\"bad frame detected, reason: green > green_min_val\")\n",
    "        return False\n",
    "    if blue <= blue_min_val:\n",
    "        logging.warning(\"bad frame detected, reason: blue > blue_min_val\")\n",
    "        return False\n",
    "    if red <= green:\n",
    "        logging.warning(\"bad frame detected, reason: red > green\")\n",
    "        return False\n",
    "    if red <= blue:\n",
    "        logging.warning(\"bad frame detected, reason: red > blue\")\n",
    "        return False\n",
    "    if abs(red - green) <= red_green_max_diff:\n",
    "        logging.warning(\"bad frame detected, reason: abs(red - green) > red_green_max_diff\")\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_new_frame(vidcap):\n",
    "    success, next_image = vidcap.read()\n",
    "    return success, next_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting RGB arrays results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_result(greens, reds, blues, x_value, title=\"\"):\n",
    "    logging.info(\"Plotting results ...\" + title)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(x_value, greens, color=\"green\")\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(x_value, reds, color=\"red\")\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(x_value, blues, color=\"blue\")\n",
    "    plt.show()\n",
    "    logging.info(\"Showing result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_channel(channel,fs):\n",
    "    \"\"\"\n",
    "    This method apply filter on a channel between 0.75HZ to 4HZ.\n",
    "    :param channel: Is a signal to apply the filter to.\n",
    "    :param fs: Is the sampling rate of channel.\n",
    "    :return: The filtered channel.\n",
    "    \"\"\"\n",
    "    bh, ah = sig.butter(4, 0.75 / (fs / 2), 'highpass')\n",
    "    bl, al = sig.butter(4, 4 / (fs / 2), 'lowpass')\n",
    "    try:\n",
    "        channel = sig.filtfilt(bh, ah, channel) # applying the filter coefficient on the sig\n",
    "    except:\n",
    "        return None\n",
    "    #channel = np.absolute(channel)\n",
    "    channel_after_filter = sig.filtfilt(bl, al, channel) # applying the filter coefficient on the sig\n",
    "    return channel_after_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting RGB values from a frame and adding them to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_luminace(red, green, blue):\n",
    "    luminance_level = 0.2126 * red + 0.7152 * green + 0.0722 * blue\n",
    "    return luminance_level\n",
    "def parse_RGB(rois, color_sig):\n",
    "    \"\"\"\n",
    "    Parses an image to its RGB channels\n",
    "    :param image: the image to be parsed\n",
    "    :param vidcap:\n",
    "    :param greens: array containing green channel values\n",
    "    :param blues: array containing blue channel values\n",
    "    :param reds: array containing red channel values\n",
    "    :param frame_number - is the number of the frame of the video.\n",
    "    :return: a flag indicating if there is a next image, and the next image\n",
    "    \"\"\"\n",
    "#     plt.imshow(roi)\n",
    "#     plt.show()\n",
    "    try:\n",
    "        for r in roi:\n",
    "            cv2.cvtColor(r, cv2.COLOR_RGB2BGR)\n",
    "    except:\n",
    "        return False, color_sig\n",
    "    for i,r in enumerate(roi):\n",
    "        try:\n",
    "            new_blue,new_green,new_red = cv2.split(r)\n",
    "        except:\n",
    "            logging.info(\"falied to parse roi\")\n",
    "            return None\n",
    "        b_mean,g_mean,r_mean = np.mean(new_blue),np.mean(new_green),np.mean(new_red)\n",
    "        luminance_level = parse_luminace(r_mean, g_mean, b_mean)\n",
    "        if good_frame(b_mean,g_mean,r_mean):\n",
    "            color_channels = r.reshape(-1, r.shape[-1])\n",
    "            avg_color = color_channels.mean(axis=0)\n",
    "            color_sig[i].append(avg_color)\n",
    "            return True, color_sig, luminance_level\n",
    "    return False, color_sig, luminance_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_video_details(video_source):\n",
    "    logging.info(\"\\nInformation on video:\\t\\t\\t\\t\\t\\t\" + str(video_source) +\n",
    "                 \"\\nFPS:\\t\\t\\t\\t\\t\\t\" + str(fps) + \n",
    "                 \"\\nRound FPS:\\t\\t\\t\\t\\t\\t\" + str(round_fps) + \n",
    "                 \"\\nNumber of frames:\\t\\t\\t\\t\" + str(number_of_frames) + \n",
    "                 \"\\nNumber of bad frames:\\t\\t\\t\\t\" + str(bad_frames) + \n",
    "                 \"\\nMax luminanace:\\t\\t\\t\\t\\t\" + str(max_luminance) + \n",
    "                 \"\\nMin luminanace:\\t\\t\\t\\t\\t\" + str(min_luminance) +\n",
    "                 \"\\nMax diff of luminanace between adjacent frames:\\t\" + str(max_diff_luminance_adjacent) +\n",
    "                 \"\\nAvg luminanace:\\t\\t\\t\\t\\t\" + str(avg_luminance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def indexes(y, thres=0.3, min_dist=1, thres_abs=False):\n",
    "    if isinstance(y, np.ndarray) and np.issubdtype(y.dtype, np.unsignedinteger):\n",
    "        raise ValueError(\"y must be signed\")\n",
    "\n",
    "    if not thres_abs:\n",
    "        thres = thres * (np.max(y) - np.min(y)) + np.min(y)\n",
    "\n",
    "    min_dist = int(min_dist)\n",
    "\n",
    "    # compute first order difference\n",
    "    dy = np.diff(y)\n",
    "\n",
    "    # propagate left and right values successively to fill all plateau pixels (0-value)\n",
    "    zeros, = np.where(dy == 0)\n",
    "\n",
    "    # check if the signal is totally flat\n",
    "    if len(zeros) == len(y) - 1:\n",
    "        return np.array([])\n",
    "\n",
    "    if len(zeros):\n",
    "        # compute first order difference of zero indexes\n",
    "        zeros_diff = np.diff(zeros)\n",
    "        # check when zeros are not chained together\n",
    "        zeros_diff_not_one, = np.add(np.where(zeros_diff != 1), 1)\n",
    "        # make an array of the chained zero indexes\n",
    "        zero_plateaus = np.split(zeros, zeros_diff_not_one)\n",
    "\n",
    "        # fix if leftmost value in dy is zero\n",
    "        if zero_plateaus[0][0] == 0:\n",
    "            dy[zero_plateaus[0]] = dy[zero_plateaus[0][-1] + 1]\n",
    "            zero_plateaus.pop(0)\n",
    "\n",
    "        # fix if rightmost value of dy is zero\n",
    "        if len(zero_plateaus) and zero_plateaus[-1][-1] == len(dy) - 1:\n",
    "            dy[zero_plateaus[-1]] = dy[zero_plateaus[-1][0] - 1]\n",
    "            zero_plateaus.pop(-1)\n",
    "\n",
    "        # for each chain of zero indexes\n",
    "        for plateau in zero_plateaus:\n",
    "            median = np.median(plateau)\n",
    "            # set leftmost values to leftmost non zero values\n",
    "            dy[plateau[plateau < median]] = dy[plateau[0] - 1]\n",
    "            # set rightmost and middle values to rightmost non zero values\n",
    "            dy[plateau[plateau >= median]] = dy[plateau[-1] + 1]\n",
    "\n",
    "    # find the peaks by using the first order difference\n",
    "    peaks = np.where(\n",
    "        (np.hstack([dy, 0.0]) < 0.0)\n",
    "        & (np.hstack([0.0, dy]) > 0.0)\n",
    "        & (np.greater(y, thres))\n",
    "    )[0]\n",
    "\n",
    "    # handle multiple peaks, respecting the minimum distance\n",
    "    if peaks.size > 1 and min_dist > 1:\n",
    "        highest = peaks[np.argsort(y[peaks])][::-1]\n",
    "        rem = np.ones(y.size, dtype=bool)\n",
    "        rem[peaks] = False\n",
    "\n",
    "        for peak in highest:\n",
    "            if not rem[peak]:\n",
    "                sl = slice(max(0, peak - min_dist), peak + min_dist + 1)\n",
    "                rem[sl] = True\n",
    "                rem[peak] = False\n",
    "\n",
    "        peaks = np.arange(y.size)[~rem]\n",
    "\n",
    "    return peaks\n",
    "\n",
    "def print_results(window_sig, window, xlabel, ylabel, change_range, title):\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(title)\n",
    "    ax = fig.subplots()\n",
    "    while len(window_sig) > len(window):\n",
    "        window_sig = window_sig[:-1]\n",
    "    ax.plot(window_sig,window,color ='green')\n",
    "    if change_range:\n",
    "        plt.xlim([0, 5])\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xscale('linear')\n",
    "    ax.spines['bottom'].set_color('red')\n",
    "    ax.spines['left'].set_color('red')\n",
    "    ax.xaxis.label.set_color('red')\n",
    "    ax.yaxis.label.set_color('red')\n",
    "    ax.tick_params(axis='x', colors='red')\n",
    "    ax.tick_params(axis='y', colors='red')\n",
    "    plt.show()\n",
    "\n",
    "import scipy\n",
    "def find_peaks_with_scipy(window_sig, window, round_fps, hr):\n",
    "    peaks, _ = scipy.signal.find_peaks(window, distance=round_fps)\n",
    "    plt.plot(window_sig,window,'-go',markerfacecolor='red',markevery=peaks)\n",
    "    plt.title(\"Peaks with scipy\")\n",
    "    plt.show()\n",
    "    logging.info(\"Peaks vector with scipy: \" + str(peaks) + \" num of peaks: \" + str(len(peaks)))\n",
    "\n",
    "def print_peaks(window_sig, window):\n",
    "    while len(window_sig) > len(window):\n",
    "        window_sig = window_sig[:-1]\n",
    "        \n",
    "    peaks = indexes(window,min_dist=20)\n",
    "    plt.plot(window_sig,window,'-go',markerfacecolor='red',markevery=peaks)\n",
    "    plt.title(\"Peaks with implemented function\")\n",
    "    plt.show()\n",
    "    logging.info(\"Peaks vector by implemented function: \" + str(window_sig[peaks]) + \" num of peaks: \" + str(len(window_sig[peaks])))\n",
    "    #print(window_sig)\n",
    "    #test_peaks = find_peaks(window_sig)\n",
    "    #plt.plot(window_sig,window,'-go',markerfacecolor='red',markevery=test_peaks)\n",
    "    #np.savetxt(\"time_of_peaks.csv\", x[peaks], delimiter=\",\")\n",
    "    \n",
    "def find_hr_in_window(green, window_start, round_fps, window_id, window_size):\n",
    "    \n",
    "    round_fps = int(round_fps)\n",
    "    if window_start + round_fps * window_size > len(green):\n",
    "        window = green[window_start : ]\n",
    "    else:\n",
    "        window = green[window_start : window_start + round_fps * window_size]\n",
    "    window_sig = np.arange(window.size/round_fps,step= (1/round_fps))\n",
    "    \n",
    "    print_results(window_sig, window, 'X-axis', 'Y-axis', False, \"Green signal\")\n",
    "\n",
    "    window = window - np.mean(window)\n",
    "    window = window / np.std(window)\n",
    "    print_results(window_sig, window, 'X-axis', 'Y-axis', False, \"Green signal normalized\")\n",
    "    \n",
    "    g = filter_channel(window,round_fps)\n",
    "    if g is None:\n",
    "        return\n",
    "    from skimage.restoration import denoise_wavelet\n",
    "    g = denoise_wavelet(g,wavelet='sym2',wavelet_levels = 4)\n",
    "    print_peaks(window_sig, g)\n",
    "    print_results(window_sig, window, 'X-axis', 'Y-axis', False, \"\")\n",
    "\n",
    "    f, Pxx_den = sig.periodogram(g, round_fps)\n",
    "    \n",
    "    print_results(f, Pxx_den, 'Frequency [Hz]', 'PSD [V**2/Hz]', True, \"PSD by Frequency\")\n",
    "    # plt.semilogy(f, Pxx_den)\n",
    "    # plt.ylim([1e-7, 1e2])\n",
    "    # plt.xlabel('frequency [Hz]')\n",
    "    # plt.ylabel('PSD [V**2/Hz]')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    max_val = Pxx_den.argmax()\n",
    "    logging.info(\"Window \" + str(window_id) +\n",
    "                 \":\\nHighest freq:\" + str(f[max_val]) + \"\\nHeart rate: \" + str(f[max_val]*60))\n",
    "    \n",
    "    find_peaks_with_scipy(window_sig, g,round_fps, f[max_val]*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.covariance import MinCovDet as MCD\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy,itertools\n",
    "from skimage.restoration import denoise_wavelet\n",
    "\n",
    "def eigenvalue_decomposition(mat):\n",
    "        \"\"\" return (diagonal,orthogonal matrix)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # eigen_vals, eigen_vectors\n",
    "        eigen_vals, eigen_vectors = np.linalg.eigh(mat)\n",
    "        d = np.diag(eigen_vals)\n",
    "        return d,eigen_vectors\n",
    "\n",
    "def cartesian_product(xi,v):\n",
    "    cartez_prod = list(itertools.product(xi,v))\n",
    "    return np.asarray(cartez_prod).T\n",
    "    \n",
    "def multivariate_video_signal(signal):\n",
    "    \"\"\"\n",
    "    Algorithm 1\n",
    "    :param signal: is a 2D signal. One dimension the signal from the forehead, and second is from above the upper lip\n",
    "    :return: multivariate PPG!\n",
    "    \"\"\"\n",
    "    H, J = 2, 4\n",
    "    num_of_sampels = signal.shape[1]\n",
    "    wavelet = pywt.Wavelet('sym2') \n",
    "    coeff_all = pywt.wavedec(signal, wavelet, level=J) \n",
    "    approx_4,det_4,det_3,det_2,det_1 = coeff_all\n",
    "    details = [det_1,det_2,det_3,det_4]\n",
    "    noise_mat = MCD(random_state=0).fit(details[0].T).covariance_\n",
    "    # decomposing noise matrix: \n",
    "    d,v = eigenvalue_decomposition(noise_mat) # noise_matrix = v * d *v.T\n",
    "    diag_vals = d.diagonal()\n",
    "    xi_hats = []\n",
    "    for j in range(0, J ):\n",
    "        xi_j = np.dot(details[j].T,v).T\n",
    "#         xi_j = cartesian_product(details[j].T,v)\n",
    "        xi_hat_hs = []\n",
    "        for h in range(0, H):\n",
    "            gama_h = np.sqrt(2 * diag_vals[h] * np.log(num_of_sampels))\n",
    "            xi_hat_hs.append(pywt.threshold(data=xi_j[h], value=gama_h))\n",
    "        xi_hats.append(np.vstack((xi_hat_hs[0],xi_hat_hs[1])))\n",
    "    # scaling function basis change:\n",
    "    phi = approx_4.T\n",
    "    pca = PCA()\n",
    "    phi_norm = StandardScaler().fit_transform(phi) # normalize \n",
    "    pca.fit(phi_norm)\n",
    "    phi_hat = pca.transform(phi_norm).T # new scaling function\n",
    "    #reconstructing the signal:\n",
    "    coeffs = list(reversed(xi_hats))\n",
    "    coeffs.insert(0,phi_hat) # coeeffs is in a form of [cA4,cD4,cD3,cD2,cD1]\n",
    "    multivariate_ppg = pywt.waverec(coeffs,wavelet) # reconstruction\n",
    "    return multivariate_ppg\n",
    "\n",
    "# data that i used to test the algorithm:\n",
    "# x = pywt.data.ecg().astype(float) / 256\n",
    "# y = pywt.data.ecg().astype(float) / 256\n",
    "# sigma = 0.05\n",
    "# x_noisy = x + sigma * np.random.randn(x.size)\n",
    "# y_noisy = x + 2*sigma * np.random.randn(y.size)\n",
    "# combined = np.vstack((x_noisy, y_noisy)) # making 2d array\n",
    "def mvd(color_sig):\n",
    "    print(color_sig)\n",
    "    ppg_hat = multivariate_video_signal(color_sig)\n",
    "\n",
    "# plt.plot(ppg_hat,color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def detect_hr(video_source):\n",
    "    logging.info(\"\\n=======================\\n\" + video_source + \"\\n=======================\\n\")\n",
    "    color_sig_array = np.asarray(color_sig)\n",
    "    color_sig_array = mvd(color_sig_array)\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(color_sig_array[0],\"red\")\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.show()\n",
    "    red = color_sig_array[0][:,0]\n",
    "    green = color_sig_array[0][:,1]\n",
    "    blue = color_sig_array[0][:,2]\n",
    "\n",
    "    window_start = 0\n",
    "    window_size = 30\n",
    "    window_id = 0\n",
    "    limit = good_frame_number - int(round_fps) * window_size\n",
    "    while window_start < limit :\n",
    "        find_hr_in_window(green, window_start, round_fps, window_id, window_size)\n",
    "        window_start += int(round_fps) * window_size\n",
    "        window_id += 1\n",
    "    if window_start < good_frame_number:\n",
    "        find_hr_in_window(green, window_start, round_fps, window_id, good_frame_number - window_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Main loop - going over all the frames of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-22 10:49:42,613] [INFO] [<module>] [7] : Working on video rotated_first_video.mp4\n",
      "[2021-05-22 10:49:42,745] [INFO] [<module>] [13] : Parsing images ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 3)\n",
      "===============\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-22 10:49:48,065] [INFO] [parse_RGB] [31] : falied to parse roi\n",
      "[2021-05-22 10:49:48,067] [ERROR] [<module>] [43] : failed to get output from parse_RGB!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 3)\n",
      "===============\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-22 10:49:51,237] [INFO] [parse_RGB] [31] : falied to parse roi\n",
      "[2021-05-22 10:49:51,239] [ERROR] [<module>] [43] : failed to get output from parse_RGB!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(511, 3)\n",
      "===============\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-22 10:49:54,326] [INFO] [parse_RGB] [31] : falied to parse roi\n",
      "[2021-05-22 10:49:54,334] [ERROR] [<module>] [43] : failed to get output from parse_RGB!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 3)\n",
      "===============\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-22 10:49:57,591] [INFO] [parse_RGB] [31] : falied to parse roi\n",
      "[2021-05-22 10:49:57,592] [ERROR] [<module>] [43] : failed to get output from parse_RGB!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 3)\n",
      "===============\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAAlCAYAAABMDyIGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJoklEQVR4nO2dbaxcRRnHf/85Z/feS1taaikvAgJC1H7QoogQ+IDEF0TQmKCBGMUEQ2KIgYRoQBMSTUzki6jBqBiNiTFqfCEiXxCBxPhBEKRAAZHWQLSiBeStcru758zjh5mze+5Nw71tb+/K7vNLNnvm5cw885+Z55ydszsrM8NxHMeZXMK4DXAcx3EOLe7oHcdxJhx39I7jOBOOO3rHcZwJxx294zjOhOOO3nEcZ8JZlqOXdL6kxyXtkHTtPtJnJP0sp98j6cQVt9RxHMc5IJZ09JIK4FvAB4AtwKWStizKdjnwvJmdAtwI3LDShjqO4zgHRrmMPBcCG4DbAAP+BnwYeLSV51PAFkln5vCpkmT+ayzHcZyxsxxHfyTwezP7iKR1wF+Bl/aR549m9h4ASTuB1wHPrqSxjuM4zv6zHEf/AvAcgJm9LOmfwNoDqUzSFcAVAKHsvmNu7WZiCZatsAIsAKXRKSvWdXocHuYpFDGEMET6WJGOQBgRLYjXMBVC6xwW5QGIw3JGeStENBG08ANJtEBE1ARK6mF8TSBaAAxDVFYQFAkYkUBtyT7JhvU2+QAKIpbLLxRRrtcs5W6fGzAGVtCPJUFGaJUZMIJibm9qA0BlgTqX3eQX0IslheJQB2U9G/uGmpmQDMvltfUbaoMwa9IYtqEpswk1ujb9lspv9ZtGZQ771KCQtfoq2R+Uyu3HEqxdZ6PLQruiaahpt6gXaNycV8ViVDlQKDJbVLkNycZGz9oCZiBBqZj6DqO2QGWBIBvqW1ugq5rZMCC04gxR53EVsDzWR21v8jT1t/vSLIXJWtQxEHNfpfGqYVoZIoNYYAZlGNW/uB8bTaoYcl+0xmJTXohIEGPuD6U+Gp4PYE2aDd8Xan3wjMbKvhcOXrUONW+jc9s+pQk3ujfVNH3TdFCjMUCsAqoEEWSgCKrSOxiNO7GmgADNcBtN9FHYQvaJBRBGdvaf2vWsmR35as1bzHIc/S7geID8kPWNwG8W5XkGeKekB4GngY3ki0MbM7sZuBlg/czRdpbeD5s3M9i8FiIM1pX01hfMbwq8cqwRT9jLCUc/w5pOjyCjG2rmigFBRiekiVqqTo4VY2CNw4VOqBnEgrmiz0yoGFhBFQsGFpivO0ByHr26JCK6oaKTJ+BzvTXsrUeONCg52PmqQ68u6dUFM0VNkSfMK4MO/Sr1WFUX9PolRREpiki/X1JXBQaUZT0cnGYw6JWYibJTYybqKhDKSAgRTMQYiLUIhUFjRxFhzwzd+QIrDMo4HByhW6MiO7haxEEBETq9AvWFdSydkwfNzJ6C2MkTsdJooOVBSjORY4pXBNXpla9rafCaUp4mTE4HrLDhMUDoK1/QjVC3pmIEwtA/5DKybQZ1F0KV6iDkSaCUVu5pBGgmhxHzyFYNihpOulCn8wbrLLWpGrXBgtF9WSP7DWIXehvjqA0y5voi9EWxV4QKYgn1rBG7+YJbiWJeWGHUM027oVpjxPUVsZPGDf2AgLKfHISVBh1DtSAYiqIYKPWDUjj0ROhD7KSuKuZT22IJxV4o+tk5CMIgtS12oJqDzp7U3mpNalvRG/VV2wmFAXRftlFf5Liyl3St5kQsU5uadNWNjmmchDr1uwVhIdtbQTFIFdWdoaddNJZa46c1FmXZKeZ+T/0sFG3BuBuOHaW6ZW3v3E4fjXdrjXsWjL9R2JTGn+LI3jCw0ZgUHPZszezuHsWeHqoi2tvHXnwJ6gqKAsoSzXSh28GKQDx8jt6muXRRqAwrRSxGdu09ouC/Rwf6RxiDdRHrGBqIpz77uafYT7TUMrqkkrRccxHwI5IT/6CZPdLKcw3wFjP7tKSvAlea2bp9lDW8owfeRLoY+PIObMJ1ANehwXUY4Vok2jq8YX/v6Jd09ACSLgJ+CswDN5rZVyR9GbjPzG6VNEu6CJwG/Ac4FthqZq/aQZLuM7PT98fgScR1SLgOCddhhGuROFgdlly6kSTgo8D3zOzqJt7Mrm9l2wB8zMxM0hnAL9jH0o3jOI6z+ixnjf5s4BPAw5K25bgvACcAmNl3gIuBz0iqSHf9l/hXKx3Hcf4/WNLRm9kfWOIBtpndBNx0APXffADnTCKuQ8J1SLgOI1yLxEHpsKw1esdxHOe1i29q5jiOM+GMxdEvtUnapCHpB5J2S9reitso6Q5JT+T3I3K8JH0za/OQpLePz/KVQ9Lxku6W9KikRyRdleOnSgcASbOS7pX0YNbiSzn+pLwp4I68SWA3x0/0poGSCkkPSLoth6dOB0lPSnpY0jZJ9+W4FZsbq+7ol7lJ2qTxQ+D8RXHXAnea2anAnTkMSZdT8+sK4NurZOOhpgKuMbMtwJnAlbnfp00HgB5wnpm9DdgKnJ/3ibqB9PXlU4DnSZsFwuRvGngV8FgrPK06vNvMtra+Rrlyc8PMVvUFnAXc3gpfB1y32naMod0nAttb4ceBY/LxMcDj+fi7wKX7yjdJL+DXwHtdBw4D/gy8i/SDmDLHD+cJcDtwVj4ucz6N2/YVav9x2YmdR9o4UVOqw5PApkVxKzY3xrF083rg763wP3LctHGUmT2dj/8FHJWPJ16f/JH7NOAeplSHvFyxDdgN3AHsBF4wsypnabd3qEVOf5G0aeAk8HXg86RNMCC1axp1MOC3ku7POwjACs6N5XyP3jnEmJlJi3frmEwkrQV+CVxtZi+ptYvZNOlgZjWwVdIG4BbgzeO1aPWRdCGw28zul3TumM0ZN+eY2S5Jm4E7JP2lnXiwc2Mcd/TDTdIyx+W4aePfko4ByO+7c/zE6iOpQ3LyPzazX+XoqdOhjZm9ANxNWqLYkPeWgoXtbW8sWALrmYxfnp8NfEjSk6QtVs4DvsH06YCZ7crvu0kX/jNYwbkxDkf/J9Ifk5yUn6ZfAtw6BjvGza3AZfn4MtKadRP/yfxk/UzgxdbHt9csSrfu3wceM7OvtZKmSgcASUfmO3kkzZGeVTxGcvgX52yLtWg0uhi4y/Li7GsZM7vOzI4zsxNJfuAuM/s4U6aDpDVK//WBpDXA+4DtrOTcGNODhwtIO2LuBL447gchq9Den5C2bx6Q1tMuJ60t3gk8AfwO2JjzivStpJ3Aw8Dp47Z/hTQ4h7QO+RCwLb8umDYdctveCjyQtdgOXJ/jTwbuBXYAPwdmcvxsDu/I6SePuw2HQJNzgdumUYfc3gfz65HGJ67k3PBfxjqO40w4/stYx3GcCccdveM4zoTjjt5xHGfCcUfvOI4z4bijdxzHmXDc0TuO40w47ugdx3EmHHf0juM4E87/ANmRtA9fftVhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-05-22 10:50:01,943] [INFO] [parse_RGB] [31] : falied to parse roi\n",
      "[2021-05-22 10:50:01,978] [ERROR] [<module>] [43] : failed to get output from parse_RGB!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-173-bcd9de744572>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtotal_frame_number\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;36m100\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m             \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Parsing frame \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtotal_frame_number\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"/\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnumber_of_frames\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m         \u001B[0mrois\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparse_roi\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcvtColor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCOLOR_BGR2RGB\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# build image ROI (rois is a tuple contains two regions)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mrois\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m             \u001B[0mroi\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvstack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrois\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrois\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-163-9a2a7b10245a>\u001B[0m in \u001B[0;36mparse_roi\u001B[0;34m(frame)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mparse_roi\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;31m# image = face_recognition.load_image_file(frame) # read image.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mface_locations\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mface_recognition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mface_locations\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'hog'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# detects all the faces in image\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mface_landmarks_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mface_recognition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mface_landmarks\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/face_recognition/api.py\u001B[0m in \u001B[0;36mface_locations\u001B[0;34m(img, number_of_times_to_upsample, model)\u001B[0m\n\u001B[1;32m    119\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0m_trim_css_to_bounds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_rect_to_css\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mface\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrect\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mface\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_raw_face_locations\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_times_to_upsample\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"cnn\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    120\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 121\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0m_trim_css_to_bounds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_rect_to_css\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mface\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mface\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_raw_face_locations\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_times_to_upsample\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    122\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/face_recognition/api.py\u001B[0m in \u001B[0;36m_raw_face_locations\u001B[0;34m(img, number_of_times_to_upsample, model)\u001B[0m\n\u001B[1;32m    103\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcnn_face_detector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_times_to_upsample\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 105\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mface_detector\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_times_to_upsample\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Parsing video:\n",
    "for video_location in rotated_video_sources:\n",
    "    color_sig = [[]]\n",
    "    heart_rates = []\n",
    "    good_frame_number = 0\n",
    "    total_frame_number = 180\n",
    "    logging.info(\"Working on video \" + video_location)\n",
    "    vidcap = cv2.VideoCapture(video_location)\n",
    "    success, image = vidcap.read()\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS) # fs == sampling rate\n",
    "    round_fps = np.round(fps)\n",
    "    number_of_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    logging.info(\"Parsing images ...\")\n",
    "    skipped_frames = 0\n",
    "    bad_frames = 0\n",
    "    max_luminance = 0\n",
    "    min_luminance = 200\n",
    "    avg_luminance = 0\n",
    "    perv_luminance = None\n",
    "    max_diff_luminance_adjacent = 0\n",
    "\n",
    "    while success:\n",
    "        if skipped_frames < 180:\n",
    "            skipped_frames += 1\n",
    "            success, image = get_new_frame(vidcap)\n",
    "            continue\n",
    "        if total_frame_number % 100 == 0:\n",
    "            logging.info(\"Parsing frame \" + str(total_frame_number) + \"/\" + str(number_of_frames))\n",
    "        rois = parse_roi(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # build image ROI (rois is a tuple contains two regions)\n",
    "        if rois is not None :\n",
    "            roi = np.vstack((rois[0], rois[1]))\n",
    "            try:\n",
    "                is_good_frame,color_sig, luminance_level = parse_RGB(roi, color_sig)\n",
    "                if perv_luminance is not None and luminance_level - perv_luminance > max_diff_luminance_adjacent:\n",
    "                    max_diff_luminance_adjacent = luminance_level - perv_luminance\n",
    "                if luminance_level > max_luminance:\n",
    "                    max_luminance = luminance_level\n",
    "                if luminance_level < min_luminance:\n",
    "                    min_luminance = luminance_level\n",
    "                avg_luminance += luminance_level\n",
    "                perv_luminance = luminance_level\n",
    "            except:\n",
    "                logging.error(\"failed to get output from parse_RGB!\")\n",
    "                is_good_frame = False\n",
    "                bad_frames += 1\n",
    "            if is_good_frame:\n",
    "                good_frame_number += 1\n",
    "                #logging.info(\"luminance level: \" + str(luminance_level))\n",
    "        if roi is None:\n",
    "            bad_frames += 1\n",
    "        total_frame_number += 1\n",
    "        success, image = get_new_frame(vidcap)\n",
    "    avg_luminance /= total_frame_number\n",
    "    log_video_details(video_location)\n",
    "    detect_hr(video_location)\n",
    "    #except:\n",
    "    #    logging.warning(\"Issue in detecting hr in video\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}