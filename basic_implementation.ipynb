{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Basic implementation using jupyter notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging, numpy as np\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import platform\n",
    "\n",
    "FORMAT = '[%(asctime)s] [%(levelname)s] [%(funcName)s] [%(lineno)d] : %(message)s'\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "logging.info(\"Starting ...\")\n",
    "if platform.system() == \"Windows\":\n",
    "    seperator = \"\\\\\"\n",
    "else:\n",
    "    seperator = \"/\"\n",
    "\n",
    "dir = \"perry-all-2\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot results:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_result(greens, reds, blues, x_value, title=\"\"):\n",
    "    logging.info(\"Plotting results ...\" + title)\n",
    "    x_value = x_value.reshape(1, 179)\n",
    "    r = reds.tolist()[0]\n",
    "    b = blues.tolist()[0]\n",
    "    g = greens.tolist()[0]\n",
    "    x = x_value.tolist()[0]\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(x, g, color=\"green\")\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(x, r, color=\"red\")\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(x, b, color=\"blue\")\n",
    "    plt.show()\n",
    "    logging.info(\"Showing result\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### rotate image:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rotate_image(mat, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image (angle in degrees) and expands image to avoid cropping\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = mat.shape[:2]  # image shape has 3 dimensions\n",
    "    image_center = (\n",
    "        width / 2,\n",
    "        height / 2)  # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to shape\n",
    "\n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
    "\n",
    "    # rotation calculates the cos and sin, taking absolutes of those.\n",
    "    abs_cos = abs(rotation_mat[0, 0])\n",
    "    abs_sin = abs(rotation_mat[0, 1])\n",
    "\n",
    "    # find the new width and height bounds\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    # subtract old image center (bringing image back to origo) and adding the new image center coordinates\n",
    "    rotation_mat[0, 2] += bound_w / 2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h / 2 - image_center[1]\n",
    "\n",
    "    # rotate image with the new bounds and translated rotation matrix\n",
    "    rotated_mat = cv2.warpAffine(mat, rotation_mat, (bound_w, bound_h))\n",
    "    return rotated_mat\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parse roi:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_roi(image):\n",
    "    \"\"\"\n",
    "    Upon receiving an image, finds a face (if exists) and writes it as an image\n",
    "    :param image: the image to be parsed\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # perform grayscale\n",
    "    flag_face_detected = False\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    face = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    for (x, y, w, h) in face:\n",
    "        flag_face_detected = True\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        roi_color = image[y:y + h, x:x + w]\n",
    "        # print(\"[INFO] Object found. Saving locally.\")\n",
    "        cv2.imwrite('faces_detected.jpg', roi_color)\n",
    "        roi_color_rgb = cv2.cvtColor(roi_color, cv2.COLOR_BGR2RGB)\n",
    "        # plt.imshow(roi_color_rgb)\n",
    "        # plt.show()\n",
    "    if not flag_face_detected:\n",
    "        logging.warning(\"No face detected in image\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### calculate mean:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_RGB(image, vidcap, greens, reds, blues, frame_number):\n",
    "    \"\"\"\n",
    "    Parses an image to its RGB channels\n",
    "    :param image: the image to be parsed\n",
    "    :param vidcap:\n",
    "    :param greens: array containing green channel values\n",
    "    :param blues: array containing blue channel values\n",
    "    :param reds: array containing red channel values\n",
    "    :param frame_number - is the number of the frame of the video.\n",
    "    :return: a flag indicating if there is a next image, and the next image\n",
    "    \"\"\"\n",
    "    blue, green, red = cv2.split(image)\n",
    "    greens[0, frame_number] = np.mean(green)\n",
    "    blues[0, frame_number] = np.mean(blue)\n",
    "    reds[0, frame_number] = np.mean(red)\n",
    "    success, image = vidcap.read()\n",
    "    return success, image\n",
    "\n",
    "\n",
    "# %% md\n",
    "\n",
    "### Butter filter:\n",
    "\n",
    "# %%s\n",
    "def apply_butter_filter(sig,fs):\n",
    "    \"\"\"\n",
    "    Filter signal using Butter filter method.\n",
    "    :param sig: is the signal to be filtered\n",
    "    :return: the filtered signal\n",
    "    \"\"\"\n",
    "    fc = np.array([0.1,4])\n",
    "    wn =2*fc/fs\n",
    "    b, a = signal.butter(4, wn, btype='bandpass')\n",
    "    filt = signal.lfilter(b, a, sig)\n",
    "    return filt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### read video frames:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_location = \"..\" + seperator + \"dataset\" + seperator + \"good_sync\" + seperator\n",
    "specific_dir = dir\n",
    "video_location = dataset_location + specific_dir + seperator + \"test.mp4\"\n",
    "logging.info(\"Working on video \" + video_location)\n",
    "vidcap = cv2.VideoCapture(video_location)\n",
    "success, image = vidcap.read()\n",
    "# image = cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "number_of_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "x_value = np.arange(np.ceil(number_of_frames / fps), step=(1 / 30))\n",
    "greens = np.zeros((1, int(number_of_frames)))  # instead of lists\n",
    "reds = np.zeros((1, int(number_of_frames)))\n",
    "blues = np.zeros((1, int(number_of_frames)))\n",
    "x_value = x_value[:-1]\n",
    "frame_number = 0\n",
    "logging.info(\"Parsing images ...\")\n",
    "while success:\n",
    "    # image = rotate_image(image, 90)\n",
    "    parse_roi(image)  # build image ROI\n",
    "    image = cv2.imread(\"faces_detected.jpg\")\n",
    "    success, image = parse_RGB(image, vidcap, greens, reds, blues, frame_number)\n",
    "    frame_number += 1\n",
    "    # image = cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    # cv2.imshow(\"Rotated (Correct)\", image)\n",
    "plot_result(greens, reds, blues, x_value, \"All 3 channels\")\n",
    "greens_buttered = apply_butter_filter(greens,fs=179)\n",
    "blues_buttered = apply_butter_filter(blues,fs=179)\n",
    "reds_buttered = apply_butter_filter(reds,fs=179)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(\"Buttered band pass\")\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(x_value.tolist(), greens_buttered.tolist()[0], color=\"green\")\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(x_value.tolist(), reds_buttered.tolist()[0], color=\"red\")\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(x_value.tolist(), blues_buttered.tolist()[0], color=\"blue\")\n",
    "plt.show()\n",
    "logging.info(\"Finished parsing the video.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Basic implementation using jupyter notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging, numpy as np\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import platform\n",
    "\n",
    "FORMAT = '[%(asctime)s] [%(levelname)s] [%(funcName)s] [%(lineno)d] : %(message)s'\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "logging.info(\"Starting ...\")\n",
    "if platform.system() == \"Windows\":\n",
    "    seperator = \"\\\\\"\n",
    "else:\n",
    "    seperator = \"/\"\n",
    "\n",
    "dir = \"perry-all-2\"\n",
    "\n",
    "\n",
    "# %% md\n",
    "\n",
    "#### Plot results:\n",
    "\n",
    "# %%\n",
    "\n",
    "def plot_result(greens, reds, blues, x_value, title=\"\"):\n",
    "    logging.info(\"Plotting results ...\" + title)\n",
    "    x_value = x_value.reshape(1, 179)\n",
    "    r = reds.tolist()[0]\n",
    "    b = blues.tolist()[0]\n",
    "    g = greens.tolist()[0]\n",
    "    x = x_value.tolist()[0]\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(x, g, color=\"green\")\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(x, r, color=\"red\")\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(x, b, color=\"blue\")\n",
    "    plt.show()\n",
    "    logging.info(\"Showing result\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### rotate image:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rotate_image(mat, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image (angle in degrees) and expands image to avoid cropping\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = mat.shape[:2]  # image shape has 3 dimensions\n",
    "    image_center = (\n",
    "        width / 2,\n",
    "        height / 2)  # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to shape\n",
    "\n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
    "\n",
    "    # rotation calculates the cos and sin, taking absolutes of those.\n",
    "    abs_cos = abs(rotation_mat[0, 0])\n",
    "    abs_sin = abs(rotation_mat[0, 1])\n",
    "\n",
    "    # find the new width and height bounds\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    # subtract old image center (bringing image back to origo) and adding the new image center coordinates\n",
    "    rotation_mat[0, 2] += bound_w / 2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h / 2 - image_center[1]\n",
    "\n",
    "    # rotate image with the new bounds and translated rotation matrix\n",
    "    rotated_mat = cv2.warpAffine(mat, rotation_mat, (bound_w, bound_h))\n",
    "    return rotated_mat\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parse roi:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_roi(image):\n",
    "    \"\"\"\n",
    "    Upon receiving an image, finds a face (if exists) and writes it as an image\n",
    "    :param image: the image to be parsed\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # perform grayscale\n",
    "    flag_face_detected = False\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    face = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "    for (x, y, w, h) in face:\n",
    "        flag_face_detected = True\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        roi_color = image[y:y + h, x:x + w]\n",
    "        # print(\"[INFO] Object found. Saving locally.\")\n",
    "        cv2.imwrite('faces_detected.jpg', roi_color)\n",
    "        roi_color_rgb = cv2.cvtColor(roi_color, cv2.COLOR_BGR2RGB)\n",
    "        # plt.imshow(roi_color_rgb)\n",
    "        # plt.show()\n",
    "    if not flag_face_detected:\n",
    "        logging.warning(\"No face detected in image\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### calculate mean:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_RGB(image, vidcap, greens, reds, blues, frame_number):\n",
    "    \"\"\"\n",
    "    Parses an image to its RGB channels\n",
    "    :param image: the image to be parsed\n",
    "    :param vidcap:\n",
    "    :param greens: array containing green channel values\n",
    "    :param blues: array containing blue channel values\n",
    "    :param reds: array containing red channel values\n",
    "    :param frame_number - is the number of the frame of the video.\n",
    "    :return: a flag indicating if there is a next image, and the next image\n",
    "    \"\"\"\n",
    "    blue, green, red = cv2.split(image)\n",
    "    greens[0, frame_number] = np.mean(green)\n",
    "    blues[0, frame_number] = np.mean(blue)\n",
    "    reds[0, frame_number] = np.mean(red)\n",
    "    success, image = vidcap.read()\n",
    "    return success, image\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Butter filter:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def apply_butter_filter(sig,fs):\n",
    "    \"\"\"\n",
    "    Filter signal using Butter filter method.\n",
    "    :param sig: is the signal to be filtered\n",
    "    :return: the filtered signal\n",
    "    \"\"\"\n",
    "    fc = np.array([0.1,4])\n",
    "    wn =2*fc/fs\n",
    "    b, a = signal.butter(4, wn, btype='bandpass')\n",
    "    filt = signal.lfilter(b, a, sig)\n",
    "    return filt\n",
    "\n",
    "\n",
    "# %% md\n",
    "\n",
    "### read video frames:\n",
    "\n",
    "# %%\n",
    "\n",
    "dataset_location = \"..\" + seperator + \"dataset\" + seperator + \"good_sync\" + seperator\n",
    "specific_dir = dir\n",
    "video_location = dataset_location + specific_dir + seperator + \"test.mp4\"\n",
    "logging.info(\"Working on video \" + video_location)\n",
    "vidcap = cv2.VideoCapture(video_location)\n",
    "success, image = vidcap.read()\n",
    "# image = cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "number_of_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "x_value = np.arange(np.ceil(number_of_frames / fps), step=(1 / 30))\n",
    "greens = np.zeros((1, int(number_of_frames)))  # instead of lists\n",
    "reds = np.zeros((1, int(number_of_frames)))\n",
    "blues = np.zeros((1, int(number_of_frames)))\n",
    "x_value = x_value[:-1]\n",
    "frame_number = 0\n",
    "logging.info(\"Parsing images ...\")\n",
    "while success:\n",
    "    # image = rotate_image(image, 90)\n",
    "    parse_roi(image)  # build image ROI\n",
    "    image = cv2.imread(\"faces_detected.jpg\")\n",
    "    success, image = parse_RGB(image, vidcap, greens, reds, blues, frame_number)\n",
    "    frame_number += 1\n",
    "    # image = cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    # cv2.imshow(\"Rotated (Correct)\", image)\n",
    "plot_result(greens, reds, blues, x_value, \"All 3 channels\")\n",
    "greens_buttered = apply_butter_filter(greens,fs=179)\n",
    "blues_buttered = apply_butter_filter(blues,fs=179)\n",
    "reds_buttered = apply_butter_filter(reds,fs=179)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(\"Buttered band pass\")\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(x_value.tolist(), greens_buttered.tolist()[0], color=\"green\")\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(x_value.tolist(), reds_buttered.tolist()[0], color=\"red\")\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(x_value.tolist(), blues_buttered.tolist()[0], color=\"blue\")\n",
    "plt.show()\n",
    "logging.info(\"Finished parsing the video.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%s\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}