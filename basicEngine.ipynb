{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Basic engine implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[2021-03-12 17:16:40,758] [INFO] [<module>] [13] : Starting ...\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import face_recognition, PIL.Image, PIL.ImageDraw,math\n",
    "import numpy as np\n",
    "import logging\n",
    "import cv2\n",
    "import platform\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.signal as sig\n",
    "\n",
    "FORMAT = '[%(asctime)s] [%(levelname)s] [%(funcName)s] [%(lineno)d] : %(message)s'\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "logging.info(\"Starting ...\")\n",
    "if platform.system() == \"Windows\":\n",
    "    seperator = \"\\\\\"\n",
    "else:\n",
    "    seperator = \"/\"\n",
    "\n",
    "dir = \"perry-all-2\"\n",
    "# should be a parameter of the engine\n",
    "dataset_location = \"..\" + seperator + \"dataset\" + seperator + \"good_sync\" + seperator\n",
    "specific_dir = dir\n",
    "video_location = dataset_location + specific_dir + seperator + \"test.mp4\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting the face landmarks and parsing the ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_roi(frame):\n",
    "    # image = face_recognition.load_image_file(frame) # read image.\n",
    "    face_locations = face_recognition.face_locations(frame,model = 'hog') # detects all the faces in image\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "    \n",
    "    # iterate through all the faces.\n",
    "    for face_location in face_locations:\n",
    "#         img = PIL.Image.open(frame)\n",
    "        img = PIL.Image.fromarray(frame)\n",
    "        top,right,bottom,left = face_location # extract all face square points.\n",
    "        diff = math.floor((top - bottom) * 0.2) # 30 percent of the face len (toadd eyebrow top point).\n",
    "        # Finding the forehead.\n",
    "        right_eyebrow_landmarks = np.asarray(face_landmarks_list[0]['right_eyebrow']) # right eyebrow points.\n",
    "        right_eyebrow_landmarks.sort(axis=0)\n",
    "        rightest_point = right_eyebrow_landmarks[-1] # The most right point of the ROI(according to x).\n",
    "        top_right_eyebrow = right_eyebrow_landmarks.min(axis = 0)[1]\n",
    "        left_eyebrow_landmarks = np.asarray(face_landmarks_list[0]['left_eyebrow'])\n",
    "        left_eyebrow_landmarks.sort(axis=0)\n",
    "        leftest_point = left_eyebrow_landmarks[0] # the most left point of ROI.(according to x)\n",
    "        top_left_eyebrow = left_eyebrow_landmarks.min(axis = 0)[1]\n",
    "        bottom = min(top_right_eyebrow,top_left_eyebrow).item(0) # bottom point of the forehead.\n",
    "        bottom = bottom - (0.05 * bottom) # improve bottom location by 2 percent.\n",
    "        forehead = img.crop((leftest_point[0], leftest_point[1]+diff, rightest_point[0],bottom)) # adding diff to top to make the forehead bigger.\n",
    "\n",
    "        # Finding the second ROI:\n",
    "        upper_mouth = np.asarray(face_landmarks_list[0]['top_lip']) # top_lip landmarks\n",
    "        upper_mouth_min = upper_mouth.min(axis = 0)[1] # The  top - lip upper point.\n",
    "        upper_nose = np.asarray(face_landmarks_list[0]['nose_bridge'])\n",
    "        upper_nose_min = upper_nose.min(axis = 0)[1]  # noise bridge upper point.\n",
    "        upper_nose_min += upper_mouth_min * 0.1 # improving the noise bridge upper point.\n",
    "        nose_to_upper_lip = img.crop((leftest_point[0], upper_nose_min, rightest_point[0], upper_mouth_min))\n",
    "#         try:\n",
    "#             concat_roi_areas = np.concatenate((forehead, nose_to_upper_lip), axis=0)\n",
    "#             cv2.imwrite('frame_roi_output.jpg', concat_roi_areas)\n",
    "        return (forehead, nose_to_upper_lip)\n",
    "#         except:\n",
    "#             logging.warning(\"concat of roi areas failed\")\n",
    "#             return None\n",
    "    return None # in case of which no face was detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%s\n"
    }
   },
   "outputs": [],
   "source": [
    "#R > 95 and G > 40 and B > 20 and R > G and R > B\n",
    "# based on https://arxiv.org/ftp/arxiv/papers/1708/1708.02694.pdf page 5\n",
    "def bad_frame(blue, green, red):\n",
    "    if red > 95 and green > 40 and blue > 20 and red >green and red > blue:\n",
    "        return False\n",
    "    logging.warning(\"bad frame detected\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting RGB values from a frame and adding them to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%s\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_RGB(image, greens, reds, blues, frame_number):\n",
    "    \"\"\"\n",
    "    Parses an image to its RGB channels\n",
    "    :param image: the image to be parsed\n",
    "    :param vidcap:\n",
    "    :param greens: array containing green channel values\n",
    "    :param blues: array containing blue channel values\n",
    "    :param reds: array containing red channel values\n",
    "    :param frame_number - is the number of the frame of the video.\n",
    "    :return: a flag indicating if there is a next image, and the next image\n",
    "    \"\"\"\n",
    "    im = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    blue, green, red = cv2.split(im)\n",
    "    if not bad_frame(np.mean(blue), np.mean(green), np.mean(red)):\n",
    "        greens[0, frame_number] = np.mean(green)\n",
    "        blues[0, frame_number] = np.mean(blue)\n",
    "        reds[0, frame_number] = np.mean(red)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%s\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_new_frame(vidcap):\n",
    "    success, image = vidcap.read()\n",
    "    return success, image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting RGB arrays results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_result(greens, reds, blues, x_value, title=\"\"):\n",
    "    logging.info(\"Plotting results ...\" + title)\n",
    "    x_value = x_value.reshape(1, x_value.shape[0])\n",
    "    r = reds.tolist()[0]\n",
    "    b = blues.tolist()[0]\n",
    "    g = greens.tolist()[0]\n",
    "    x = x_value.tolist()[0]\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(x, g, color=\"green\")\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(x, r, color=\"red\")\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(x, b, color=\"blue\")\n",
    "    plt.show()\n",
    "    logging.info(\"Showing result\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def filter_channel(channel,fs):\n",
    "    bh, ah = sig.butter(4, 0.75 / (fs / 2), 'highpass')\n",
    "    bl, al = sig.butter(4, 4 / (fs / 2), 'lowpass')\n",
    "    channel = sig.filtfilt(bh, ah, channel)\n",
    "    channel = np.absolute(channel)\n",
    "    channel_after_filter = sig.filtfilt(bl, al, channel)\n",
    "    return channel_after_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop - going over all the frames of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[2021-03-12 17:16:40,831] [INFO] [<module>] [1] : Working on video ../dataset/good_sync/perry-all-2/test.mp4\n",
      "[2021-03-12 17:16:40,858] [INFO] [<module>] [11] : Parsing images ...\n",
      "[2021-03-12 17:16:40,859] [INFO] [<module>] [13] : parsing frame 0/179.0\n",
      "[2021-03-12 17:16:41,291] [INFO] [<module>] [13] : parsing frame 1/179.0\n",
      "[2021-03-12 17:16:41,767] [INFO] [<module>] [13] : parsing frame 2/179.0\n",
      "[2021-03-12 17:16:42,229] [INFO] [<module>] [13] : parsing frame 3/179.0\n",
      "[2021-03-12 17:16:42,691] [INFO] [<module>] [13] : parsing frame 4/179.0\n",
      "[2021-03-12 17:16:43,176] [INFO] [<module>] [13] : parsing frame 5/179.0\n",
      "[2021-03-12 17:16:43,611] [INFO] [<module>] [13] : parsing frame 6/179.0\n",
      "[2021-03-12 17:16:44,066] [INFO] [<module>] [13] : parsing frame 7/179.0\n",
      "[2021-03-12 17:16:44,523] [INFO] [<module>] [13] : parsing frame 8/179.0\n",
      "[2021-03-12 17:16:44,988] [INFO] [<module>] [13] : parsing frame 9/179.0\n",
      "[2021-03-12 17:16:45,376] [INFO] [<module>] [13] : parsing frame 10/179.0\n",
      "[2021-03-12 17:16:45,756] [INFO] [<module>] [13] : parsing frame 11/179.0\n",
      "[2021-03-12 17:16:46,136] [INFO] [<module>] [13] : parsing frame 12/179.0\n",
      "[2021-03-12 17:16:46,526] [INFO] [<module>] [13] : parsing frame 13/179.0\n",
      "[2021-03-12 17:16:46,907] [INFO] [<module>] [13] : parsing frame 14/179.0\n",
      "[2021-03-12 17:16:47,303] [INFO] [<module>] [13] : parsing frame 15/179.0\n",
      "[2021-03-12 17:16:47,684] [INFO] [<module>] [13] : parsing frame 16/179.0\n",
      "[2021-03-12 17:16:48,067] [INFO] [<module>] [13] : parsing frame 17/179.0\n",
      "[2021-03-12 17:16:48,445] [INFO] [<module>] [13] : parsing frame 18/179.0\n",
      "[2021-03-12 17:16:48,828] [INFO] [<module>] [13] : parsing frame 19/179.0\n",
      "[2021-03-12 17:16:49,209] [INFO] [<module>] [13] : parsing frame 20/179.0\n",
      "[2021-03-12 17:16:49,589] [INFO] [<module>] [13] : parsing frame 21/179.0\n",
      "[2021-03-12 17:16:49,978] [INFO] [<module>] [13] : parsing frame 22/179.0\n",
      "[2021-03-12 17:16:50,357] [INFO] [<module>] [13] : parsing frame 23/179.0\n",
      "[2021-03-12 17:16:50,738] [INFO] [<module>] [13] : parsing frame 24/179.0\n",
      "[2021-03-12 17:16:51,114] [INFO] [<module>] [13] : parsing frame 25/179.0\n",
      "[2021-03-12 17:16:51,490] [INFO] [<module>] [13] : parsing frame 26/179.0\n",
      "[2021-03-12 17:16:51,868] [INFO] [<module>] [13] : parsing frame 27/179.0\n",
      "[2021-03-12 17:16:52,244] [INFO] [<module>] [13] : parsing frame 28/179.0\n",
      "[2021-03-12 17:16:52,621] [INFO] [<module>] [13] : parsing frame 29/179.0\n",
      "[2021-03-12 17:16:52,998] [INFO] [<module>] [13] : parsing frame 30/179.0\n",
      "[2021-03-12 17:16:53,375] [INFO] [<module>] [13] : parsing frame 31/179.0\n",
      "[2021-03-12 17:16:53,754] [INFO] [<module>] [13] : parsing frame 32/179.0\n",
      "[2021-03-12 17:16:54,218] [INFO] [<module>] [13] : parsing frame 33/179.0\n",
      "[2021-03-12 17:16:54,692] [INFO] [<module>] [13] : parsing frame 34/179.0\n",
      "[2021-03-12 17:16:55,159] [INFO] [<module>] [13] : parsing frame 35/179.0\n",
      "[2021-03-12 17:16:55,604] [INFO] [<module>] [13] : parsing frame 36/179.0\n",
      "[2021-03-12 17:16:56,074] [INFO] [<module>] [13] : parsing frame 37/179.0\n",
      "[2021-03-12 17:16:56,453] [INFO] [<module>] [13] : parsing frame 38/179.0\n",
      "[2021-03-12 17:16:56,904] [INFO] [<module>] [13] : parsing frame 39/179.0\n",
      "[2021-03-12 17:16:57,303] [INFO] [<module>] [13] : parsing frame 40/179.0\n",
      "[2021-03-12 17:16:57,687] [INFO] [<module>] [13] : parsing frame 41/179.0\n",
      "[2021-03-12 17:16:58,073] [INFO] [<module>] [13] : parsing frame 42/179.0\n",
      "[2021-03-12 17:16:58,476] [INFO] [<module>] [13] : parsing frame 43/179.0\n",
      "[2021-03-12 17:16:58,924] [INFO] [<module>] [13] : parsing frame 44/179.0\n",
      "[2021-03-12 17:16:59,313] [INFO] [<module>] [13] : parsing frame 45/179.0\n",
      "[2021-03-12 17:16:59,779] [INFO] [<module>] [13] : parsing frame 46/179.0\n",
      "[2021-03-12 17:17:00,238] [INFO] [<module>] [13] : parsing frame 47/179.0\n",
      "[2021-03-12 17:17:00,714] [INFO] [<module>] [13] : parsing frame 48/179.0\n",
      "[2021-03-12 17:17:01,098] [INFO] [<module>] [13] : parsing frame 49/179.0\n",
      "[2021-03-12 17:17:01,571] [INFO] [<module>] [13] : parsing frame 50/179.0\n",
      "[2021-03-12 17:17:02,043] [INFO] [<module>] [13] : parsing frame 51/179.0\n",
      "[2021-03-12 17:17:02,417] [INFO] [<module>] [13] : parsing frame 52/179.0\n",
      "[2021-03-12 17:17:02,854] [INFO] [<module>] [13] : parsing frame 53/179.0\n",
      "[2021-03-12 17:17:03,234] [INFO] [<module>] [13] : parsing frame 54/179.0\n",
      "[2021-03-12 17:17:03,671] [INFO] [<module>] [13] : parsing frame 55/179.0\n",
      "[2021-03-12 17:17:04,125] [INFO] [<module>] [13] : parsing frame 56/179.0\n",
      "[2021-03-12 17:17:04,583] [INFO] [<module>] [13] : parsing frame 57/179.0\n",
      "[2021-03-12 17:17:05,017] [INFO] [<module>] [13] : parsing frame 58/179.0\n",
      "[2021-03-12 17:17:05,393] [INFO] [<module>] [13] : parsing frame 59/179.0\n",
      "[2021-03-12 17:17:05,855] [INFO] [<module>] [13] : parsing frame 60/179.0\n",
      "[2021-03-12 17:17:06,327] [INFO] [<module>] [13] : parsing frame 61/179.0\n",
      "[2021-03-12 17:17:06,790] [INFO] [<module>] [13] : parsing frame 62/179.0\n",
      "[2021-03-12 17:17:07,223] [INFO] [<module>] [13] : parsing frame 63/179.0\n",
      "[2021-03-12 17:17:07,602] [INFO] [<module>] [13] : parsing frame 64/179.0\n",
      "[2021-03-12 17:17:08,068] [INFO] [<module>] [13] : parsing frame 65/179.0\n",
      "[2021-03-12 17:17:08,534] [INFO] [<module>] [13] : parsing frame 66/179.0\n",
      "[2021-03-12 17:17:08,992] [INFO] [<module>] [13] : parsing frame 67/179.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "logging.info(\"Working on video \" + video_location)\n",
    "vidcap = cv2.VideoCapture(video_location)\n",
    "success, image = vidcap.read()\n",
    "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "number_of_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "x_value = np.arange((number_of_frames / np.round(fps)), step=(1 / 30))\n",
    "greens = np.zeros((1, int(number_of_frames)))  # instead of lists\n",
    "reds = np.zeros((1, int(number_of_frames)))\n",
    "blues = np.zeros((1, int(number_of_frames)))\n",
    "frame_number = 0\n",
    "logging.info(\"Parsing images ...\")\n",
    "while success:\n",
    "    logging.info(\"parsing frame \" + str(frame_number) + \"/\" + str(number_of_frames))\n",
    "    # im.save(\"your_file.jpeg\")\n",
    "    roi = parse_roi(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # build image ROI\n",
    "    if roi != None: \n",
    "#     image = cv2.imread(\"frame_roi_output.jpg\") # possible BUG: read the same image twice if face not detected.\n",
    "        is_good_frame = parse_RGB(np.vstack((roi[0],roi[1])), greens, reds, blues, frame_number)\n",
    "    success, image = get_new_frame(vidcap)\n",
    "    if is_good_frame:\n",
    "        frame_number += 1\n",
    "plot_result(greens, reds, blues, x_value, \"All 3 channels\") # original signals\n",
    "\n",
    "\n",
    "green_buttered = filter_channel(greens,fps)\n",
    "red_buttered = filter_channel(reds,fps)\n",
    "blue_buttered = filter_channel(blues,fps)\n",
    "\n",
    "\n",
    "plot_result(green_buttered, red_buttered, blue_buttered, x_value, \"After Filter\") # after filtering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSD estimation using 'Welch' or 'Periodogram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, Pxx_den = sig.welch(green_buttered.tolist()[0], fps,'flattop', 1024, scaling='spectrum')\n",
    "plt.semilogy(f, Pxx_den)\n",
    "plt.ylim([1e-7, 1e2])\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD [V**2/Hz]')\n",
    "plt.show()\n",
    "\n",
    "f, Pxx_den = sig.periodogram(green_buttered.tolist()[0], fps)\n",
    "plt.semilogy(f, Pxx_den)\n",
    "plt.ylim([1e-7, 1e2])\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD [V**2/Hz]')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}